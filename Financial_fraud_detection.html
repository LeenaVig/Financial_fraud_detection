<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />

<title>AI_PROJECT</title>

<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>



<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.7.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.7.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.7.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff2?v=4.7.0') format('woff2'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.7.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.7.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.7.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.fa-pull-left {
  float: left;
}
.fa-pull-right {
  float: right;
}
.fa.fa-pull-left {
  margin-right: .3em;
}
.fa.fa-pull-right {
  margin-left: .3em;
}
/* Deprecated as of 4.4.0 */
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
.fa-pulse {
  -webkit-animation: fa-spin 1s infinite steps(8);
  animation: fa-spin 1s infinite steps(8);
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=1)";
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=2)";
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=3)";
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1)";
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1)";
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook-f:before,
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-feed:before,
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before,
.fa-gratipay:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper-pp:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-resistance:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-y-combinator-square:before,
.fa-yc-square:before,
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
.fa-buysellads:before {
  content: "\f20d";
}
.fa-connectdevelop:before {
  content: "\f20e";
}
.fa-dashcube:before {
  content: "\f210";
}
.fa-forumbee:before {
  content: "\f211";
}
.fa-leanpub:before {
  content: "\f212";
}
.fa-sellsy:before {
  content: "\f213";
}
.fa-shirtsinbulk:before {
  content: "\f214";
}
.fa-simplybuilt:before {
  content: "\f215";
}
.fa-skyatlas:before {
  content: "\f216";
}
.fa-cart-plus:before {
  content: "\f217";
}
.fa-cart-arrow-down:before {
  content: "\f218";
}
.fa-diamond:before {
  content: "\f219";
}
.fa-ship:before {
  content: "\f21a";
}
.fa-user-secret:before {
  content: "\f21b";
}
.fa-motorcycle:before {
  content: "\f21c";
}
.fa-street-view:before {
  content: "\f21d";
}
.fa-heartbeat:before {
  content: "\f21e";
}
.fa-venus:before {
  content: "\f221";
}
.fa-mars:before {
  content: "\f222";
}
.fa-mercury:before {
  content: "\f223";
}
.fa-intersex:before,
.fa-transgender:before {
  content: "\f224";
}
.fa-transgender-alt:before {
  content: "\f225";
}
.fa-venus-double:before {
  content: "\f226";
}
.fa-mars-double:before {
  content: "\f227";
}
.fa-venus-mars:before {
  content: "\f228";
}
.fa-mars-stroke:before {
  content: "\f229";
}
.fa-mars-stroke-v:before {
  content: "\f22a";
}
.fa-mars-stroke-h:before {
  content: "\f22b";
}
.fa-neuter:before {
  content: "\f22c";
}
.fa-genderless:before {
  content: "\f22d";
}
.fa-facebook-official:before {
  content: "\f230";
}
.fa-pinterest-p:before {
  content: "\f231";
}
.fa-whatsapp:before {
  content: "\f232";
}
.fa-server:before {
  content: "\f233";
}
.fa-user-plus:before {
  content: "\f234";
}
.fa-user-times:before {
  content: "\f235";
}
.fa-hotel:before,
.fa-bed:before {
  content: "\f236";
}
.fa-viacoin:before {
  content: "\f237";
}
.fa-train:before {
  content: "\f238";
}
.fa-subway:before {
  content: "\f239";
}
.fa-medium:before {
  content: "\f23a";
}
.fa-yc:before,
.fa-y-combinator:before {
  content: "\f23b";
}
.fa-optin-monster:before {
  content: "\f23c";
}
.fa-opencart:before {
  content: "\f23d";
}
.fa-expeditedssl:before {
  content: "\f23e";
}
.fa-battery-4:before,
.fa-battery:before,
.fa-battery-full:before {
  content: "\f240";
}
.fa-battery-3:before,
.fa-battery-three-quarters:before {
  content: "\f241";
}
.fa-battery-2:before,
.fa-battery-half:before {
  content: "\f242";
}
.fa-battery-1:before,
.fa-battery-quarter:before {
  content: "\f243";
}
.fa-battery-0:before,
.fa-battery-empty:before {
  content: "\f244";
}
.fa-mouse-pointer:before {
  content: "\f245";
}
.fa-i-cursor:before {
  content: "\f246";
}
.fa-object-group:before {
  content: "\f247";
}
.fa-object-ungroup:before {
  content: "\f248";
}
.fa-sticky-note:before {
  content: "\f249";
}
.fa-sticky-note-o:before {
  content: "\f24a";
}
.fa-cc-jcb:before {
  content: "\f24b";
}
.fa-cc-diners-club:before {
  content: "\f24c";
}
.fa-clone:before {
  content: "\f24d";
}
.fa-balance-scale:before {
  content: "\f24e";
}
.fa-hourglass-o:before {
  content: "\f250";
}
.fa-hourglass-1:before,
.fa-hourglass-start:before {
  content: "\f251";
}
.fa-hourglass-2:before,
.fa-hourglass-half:before {
  content: "\f252";
}
.fa-hourglass-3:before,
.fa-hourglass-end:before {
  content: "\f253";
}
.fa-hourglass:before {
  content: "\f254";
}
.fa-hand-grab-o:before,
.fa-hand-rock-o:before {
  content: "\f255";
}
.fa-hand-stop-o:before,
.fa-hand-paper-o:before {
  content: "\f256";
}
.fa-hand-scissors-o:before {
  content: "\f257";
}
.fa-hand-lizard-o:before {
  content: "\f258";
}
.fa-hand-spock-o:before {
  content: "\f259";
}
.fa-hand-pointer-o:before {
  content: "\f25a";
}
.fa-hand-peace-o:before {
  content: "\f25b";
}
.fa-trademark:before {
  content: "\f25c";
}
.fa-registered:before {
  content: "\f25d";
}
.fa-creative-commons:before {
  content: "\f25e";
}
.fa-gg:before {
  content: "\f260";
}
.fa-gg-circle:before {
  content: "\f261";
}
.fa-tripadvisor:before {
  content: "\f262";
}
.fa-odnoklassniki:before {
  content: "\f263";
}
.fa-odnoklassniki-square:before {
  content: "\f264";
}
.fa-get-pocket:before {
  content: "\f265";
}
.fa-wikipedia-w:before {
  content: "\f266";
}
.fa-safari:before {
  content: "\f267";
}
.fa-chrome:before {
  content: "\f268";
}
.fa-firefox:before {
  content: "\f269";
}
.fa-opera:before {
  content: "\f26a";
}
.fa-internet-explorer:before {
  content: "\f26b";
}
.fa-tv:before,
.fa-television:before {
  content: "\f26c";
}
.fa-contao:before {
  content: "\f26d";
}
.fa-500px:before {
  content: "\f26e";
}
.fa-amazon:before {
  content: "\f270";
}
.fa-calendar-plus-o:before {
  content: "\f271";
}
.fa-calendar-minus-o:before {
  content: "\f272";
}
.fa-calendar-times-o:before {
  content: "\f273";
}
.fa-calendar-check-o:before {
  content: "\f274";
}
.fa-industry:before {
  content: "\f275";
}
.fa-map-pin:before {
  content: "\f276";
}
.fa-map-signs:before {
  content: "\f277";
}
.fa-map-o:before {
  content: "\f278";
}
.fa-map:before {
  content: "\f279";
}
.fa-commenting:before {
  content: "\f27a";
}
.fa-commenting-o:before {
  content: "\f27b";
}
.fa-houzz:before {
  content: "\f27c";
}
.fa-vimeo:before {
  content: "\f27d";
}
.fa-black-tie:before {
  content: "\f27e";
}
.fa-fonticons:before {
  content: "\f280";
}
.fa-reddit-alien:before {
  content: "\f281";
}
.fa-edge:before {
  content: "\f282";
}
.fa-credit-card-alt:before {
  content: "\f283";
}
.fa-codiepie:before {
  content: "\f284";
}
.fa-modx:before {
  content: "\f285";
}
.fa-fort-awesome:before {
  content: "\f286";
}
.fa-usb:before {
  content: "\f287";
}
.fa-product-hunt:before {
  content: "\f288";
}
.fa-mixcloud:before {
  content: "\f289";
}
.fa-scribd:before {
  content: "\f28a";
}
.fa-pause-circle:before {
  content: "\f28b";
}
.fa-pause-circle-o:before {
  content: "\f28c";
}
.fa-stop-circle:before {
  content: "\f28d";
}
.fa-stop-circle-o:before {
  content: "\f28e";
}
.fa-shopping-bag:before {
  content: "\f290";
}
.fa-shopping-basket:before {
  content: "\f291";
}
.fa-hashtag:before {
  content: "\f292";
}
.fa-bluetooth:before {
  content: "\f293";
}
.fa-bluetooth-b:before {
  content: "\f294";
}
.fa-percent:before {
  content: "\f295";
}
.fa-gitlab:before {
  content: "\f296";
}
.fa-wpbeginner:before {
  content: "\f297";
}
.fa-wpforms:before {
  content: "\f298";
}
.fa-envira:before {
  content: "\f299";
}
.fa-universal-access:before {
  content: "\f29a";
}
.fa-wheelchair-alt:before {
  content: "\f29b";
}
.fa-question-circle-o:before {
  content: "\f29c";
}
.fa-blind:before {
  content: "\f29d";
}
.fa-audio-description:before {
  content: "\f29e";
}
.fa-volume-control-phone:before {
  content: "\f2a0";
}
.fa-braille:before {
  content: "\f2a1";
}
.fa-assistive-listening-systems:before {
  content: "\f2a2";
}
.fa-asl-interpreting:before,
.fa-american-sign-language-interpreting:before {
  content: "\f2a3";
}
.fa-deafness:before,
.fa-hard-of-hearing:before,
.fa-deaf:before {
  content: "\f2a4";
}
.fa-glide:before {
  content: "\f2a5";
}
.fa-glide-g:before {
  content: "\f2a6";
}
.fa-signing:before,
.fa-sign-language:before {
  content: "\f2a7";
}
.fa-low-vision:before {
  content: "\f2a8";
}
.fa-viadeo:before {
  content: "\f2a9";
}
.fa-viadeo-square:before {
  content: "\f2aa";
}
.fa-snapchat:before {
  content: "\f2ab";
}
.fa-snapchat-ghost:before {
  content: "\f2ac";
}
.fa-snapchat-square:before {
  content: "\f2ad";
}
.fa-pied-piper:before {
  content: "\f2ae";
}
.fa-first-order:before {
  content: "\f2b0";
}
.fa-yoast:before {
  content: "\f2b1";
}
.fa-themeisle:before {
  content: "\f2b2";
}
.fa-google-plus-circle:before,
.fa-google-plus-official:before {
  content: "\f2b3";
}
.fa-fa:before,
.fa-font-awesome:before {
  content: "\f2b4";
}
.fa-handshake-o:before {
  content: "\f2b5";
}
.fa-envelope-open:before {
  content: "\f2b6";
}
.fa-envelope-open-o:before {
  content: "\f2b7";
}
.fa-linode:before {
  content: "\f2b8";
}
.fa-address-book:before {
  content: "\f2b9";
}
.fa-address-book-o:before {
  content: "\f2ba";
}
.fa-vcard:before,
.fa-address-card:before {
  content: "\f2bb";
}
.fa-vcard-o:before,
.fa-address-card-o:before {
  content: "\f2bc";
}
.fa-user-circle:before {
  content: "\f2bd";
}
.fa-user-circle-o:before {
  content: "\f2be";
}
.fa-user-o:before {
  content: "\f2c0";
}
.fa-id-badge:before {
  content: "\f2c1";
}
.fa-drivers-license:before,
.fa-id-card:before {
  content: "\f2c2";
}
.fa-drivers-license-o:before,
.fa-id-card-o:before {
  content: "\f2c3";
}
.fa-quora:before {
  content: "\f2c4";
}
.fa-free-code-camp:before {
  content: "\f2c5";
}
.fa-telegram:before {
  content: "\f2c6";
}
.fa-thermometer-4:before,
.fa-thermometer:before,
.fa-thermometer-full:before {
  content: "\f2c7";
}
.fa-thermometer-3:before,
.fa-thermometer-three-quarters:before {
  content: "\f2c8";
}
.fa-thermometer-2:before,
.fa-thermometer-half:before {
  content: "\f2c9";
}
.fa-thermometer-1:before,
.fa-thermometer-quarter:before {
  content: "\f2ca";
}
.fa-thermometer-0:before,
.fa-thermometer-empty:before {
  content: "\f2cb";
}
.fa-shower:before {
  content: "\f2cc";
}
.fa-bathtub:before,
.fa-s15:before,
.fa-bath:before {
  content: "\f2cd";
}
.fa-podcast:before {
  content: "\f2ce";
}
.fa-window-maximize:before {
  content: "\f2d0";
}
.fa-window-minimize:before {
  content: "\f2d1";
}
.fa-window-restore:before {
  content: "\f2d2";
}
.fa-times-rectangle:before,
.fa-window-close:before {
  content: "\f2d3";
}
.fa-times-rectangle-o:before,
.fa-window-close-o:before {
  content: "\f2d4";
}
.fa-bandcamp:before {
  content: "\f2d5";
}
.fa-grav:before {
  content: "\f2d6";
}
.fa-etsy:before {
  content: "\f2d7";
}
.fa-imdb:before {
  content: "\f2d8";
}
.fa-ravelry:before {
  content: "\f2d9";
}
.fa-eercast:before {
  content: "\f2da";
}
.fa-microchip:before {
  content: "\f2db";
}
.fa-snowflake-o:before {
  content: "\f2dc";
}
.fa-superpowers:before {
  content: "\f2dd";
}
.fa-wpexplorer:before {
  content: "\f2de";
}
.fa-meetup:before {
  content: "\f2e0";
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  padding: 0;
  margin: -1px;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
div.traceback-wrapper pre.traceback {
  max-height: 600px;
  overflow: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  display: flex;
  flex-direction: row;
  justify-content: space-between;
  padding: 5px;
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
[dir="rtl"] #ipython_notebook {
  margin-right: 10px;
  margin-left: 0;
}
[dir="rtl"] #ipython_notebook.pull-left {
  float: right !important;
  float: right;
}
.flex-spacer {
  flex: 1;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#kernel_logo_widget {
  margin: 0 10px;
}
span#login_widget {
  float: right;
}
[dir="rtl"] span#login_widget {
  float: left;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
.modal-header {
  cursor: move;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
[dir="rtl"] .center-nav form.pull-left {
  float: right !important;
  float: right;
}
[dir="rtl"] .center-nav .navbar-text {
  float: right;
}
[dir="rtl"] .navbar-inner {
  text-align: right;
}
[dir="rtl"] div.text-left {
  text-align: right;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  position: absolute;
  display: block;
  width: 100%;
  height: 100%;
  overflow: hidden;
  cursor: pointer;
  opacity: 0;
  z-index: 2;
}
.alternate_upload .btn-xs > input.fileinput {
  margin: -1px -5px;
}
.alternate_upload .btn-upload {
  position: relative;
  height: 22px;
}
::-webkit-file-upload-button {
  cursor: pointer;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
ul#tabs {
  margin-bottom: 4px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
[dir="rtl"] ul#tabs.nav-tabs > li {
  float: right;
}
[dir="rtl"] ul#tabs.nav.nav-tabs {
  padding-right: 0;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons .pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .list_toolbar .col-sm-4,
[dir="rtl"] .list_toolbar .col-sm-8 {
  float: right;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: text-bottom;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
[dir="rtl"] .list_item > div input {
  margin-right: 0;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_modified {
  margin-right: 7px;
  margin-left: 7px;
}
[dir="rtl"] .item_modified.pull-right {
  float: left !important;
  float: left;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
[dir="rtl"] .item_buttons.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .item_buttons .kernel-name {
  margin-left: 7px;
  float: right;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
.sort_button {
  display: inline-block;
  padding-left: 7px;
}
[dir="rtl"] .sort_button.pull-right {
  float: left !important;
  float: left;
}
#tree-selector {
  padding-right: 0px;
}
#button-select-all {
  min-width: 50px;
}
[dir="rtl"] #button-select-all.btn {
  float: right ;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
  margin-top: 2px;
  height: 16px;
}
[dir="rtl"] #select-all.pull-left {
  float: right !important;
  float: right;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.fa-pull-left {
  margin-right: .3em;
}
.folder_icon:before.fa-pull-right {
  margin-left: .3em;
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.fa-pull-left {
  margin-right: .3em;
}
.notebook_icon:before.fa-pull-right {
  margin-left: .3em;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.fa-pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.fa-pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.fa-pull-left {
  margin-right: .3em;
}
.file_icon:before.fa-pull-right {
  margin-left: .3em;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
#new-menu .dropdown-header {
  font-size: 10px;
  border-bottom: 1px solid #e5e5e5;
  padding: 0 0 3px;
  margin: -3px 20px 0;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.move-button {
  display: none;
}
.download-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
.CodeMirror-dialog {
  background-color: #fff;
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI escape sequences */
/* The color values are a mix of
   http://www.xcolors.net/dl/baskerville-ivorylight and
   http://www.xcolors.net/dl/euphrasia */
.ansi-black-fg {
  color: #3E424D;
}
.ansi-black-bg {
  background-color: #3E424D;
}
.ansi-black-intense-fg {
  color: #282C36;
}
.ansi-black-intense-bg {
  background-color: #282C36;
}
.ansi-red-fg {
  color: #E75C58;
}
.ansi-red-bg {
  background-color: #E75C58;
}
.ansi-red-intense-fg {
  color: #B22B31;
}
.ansi-red-intense-bg {
  background-color: #B22B31;
}
.ansi-green-fg {
  color: #00A250;
}
.ansi-green-bg {
  background-color: #00A250;
}
.ansi-green-intense-fg {
  color: #007427;
}
.ansi-green-intense-bg {
  background-color: #007427;
}
.ansi-yellow-fg {
  color: #DDB62B;
}
.ansi-yellow-bg {
  background-color: #DDB62B;
}
.ansi-yellow-intense-fg {
  color: #B27D12;
}
.ansi-yellow-intense-bg {
  background-color: #B27D12;
}
.ansi-blue-fg {
  color: #208FFB;
}
.ansi-blue-bg {
  background-color: #208FFB;
}
.ansi-blue-intense-fg {
  color: #0065CA;
}
.ansi-blue-intense-bg {
  background-color: #0065CA;
}
.ansi-magenta-fg {
  color: #D160C4;
}
.ansi-magenta-bg {
  background-color: #D160C4;
}
.ansi-magenta-intense-fg {
  color: #A03196;
}
.ansi-magenta-intense-bg {
  background-color: #A03196;
}
.ansi-cyan-fg {
  color: #60C6C8;
}
.ansi-cyan-bg {
  background-color: #60C6C8;
}
.ansi-cyan-intense-fg {
  color: #258F8F;
}
.ansi-cyan-intense-bg {
  background-color: #258F8F;
}
.ansi-white-fg {
  color: #C5C1B4;
}
.ansi-white-bg {
  background-color: #C5C1B4;
}
.ansi-white-intense-fg {
  color: #A1A6B2;
}
.ansi-white-intense-bg {
  background-color: #A1A6B2;
}
.ansi-default-inverse-fg {
  color: #FFFFFF;
}
.ansi-default-inverse-bg {
  background-color: #000000;
}
.ansi-bold {
  font-weight: bold;
}
.ansi-underline {
  text-decoration: underline;
}
/* The following styles are deprecated an will be removed in a future version */
.ansibold {
  font-weight: bold;
}
.ansi-inverse {
  outline: 0.5px dotted;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  position: relative;
  overflow: visible;
}
div.cell:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: transparent;
}
div.cell.jupyter-soft-selected {
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected,
div.cell.selected.jupyter-soft-selected {
  border-color: #ababab;
}
div.cell.selected:before,
div.cell.selected.jupyter-soft-selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #42A5F5;
}
@media print {
  div.cell.selected,
  div.cell.selected.jupyter-soft-selected {
    border-color: transparent;
  }
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
}
.edit_mode div.cell.selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #66BB6A;
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  /* Note that this should set vertical padding only, since CodeMirror assumes
       that horizontal padding will be set on CodeMirror pre */
  padding: 0.4em 0;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only,
    use .CodeMirror-lines for vertical */
  padding: 0 0.4em;
  border: 0;
  border-radius: 0;
}
.CodeMirror-cursor {
  border-left: 1.4px solid black;
}
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .CodeMirror-cursor {
    border-left: 2px solid black;
  }
}
@media screen and (min-width: 4320px) {
  .CodeMirror-cursor {
    border-left: 4px solid black;
  }
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
div.output_area .mglyph > img {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 1px 0 1px 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul:not(.list-inline),
.rendered_html ol:not(.list-inline) {
  padding-left: 2em;
}
.rendered_html ul {
  list-style: disc;
}
.rendered_html ul ul {
  list-style: square;
  margin-top: 0;
}
.rendered_html ul ul ul {
  list-style: circle;
}
.rendered_html ol {
  list-style: decimal;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin-top: 0;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
  padding: 0px;
  background-color: #fff;
}
.rendered_html code {
  background-color: #eff0f1;
}
.rendered_html p code {
  padding: 1px 5px;
}
.rendered_html pre code {
  background-color: #fff;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  color: #000;
  font-size: 100%;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
.rendered_html .alert {
  margin-bottom: initial;
}
.rendered_html * + .alert {
  margin-top: 1em;
}
[dir="rtl"] .rendered_html p {
  text-align: right;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.rendered .rendered_html tr,
.text_cell.rendered .rendered_html th,
.text_cell.rendered .rendered_html td {
  max-width: none;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.text_cell .dropzone .input_area {
  border: 2px dashed #bababa;
  margin: -1px;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
.jupyter-keybindings {
  padding: 1px;
  line-height: 24px;
  border-bottom: 1px solid gray;
}
.jupyter-keybindings input {
  margin: 0;
  padding: 0;
  border: none;
}
.jupyter-keybindings i {
  padding: 6px;
}
.well code {
  background-color: #ffffff;
  border-color: #ababab;
  border-width: 1px;
  border-style: solid;
  padding: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.tags_button_container {
  width: 100%;
  display: flex;
}
.tag-container {
  display: flex;
  flex-direction: row;
  flex-grow: 1;
  overflow: hidden;
  position: relative;
}
.tag-container > * {
  margin: 0 4px;
}
.remove-tag-btn {
  margin-left: 4px;
}
.tags-input {
  display: flex;
}
.cell-tag:last-child:after {
  content: "";
  position: absolute;
  right: 0;
  width: 40px;
  height: 100%;
  /* Fade to background color of cell toolbar */
  background: linear-gradient(to right, rgba(0, 0, 0, 0), #EEE);
}
.tags-input > * {
  margin-left: 4px;
}
.cell-tag,
.tags-input input,
.tags-input button {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  box-shadow: none;
  width: inherit;
  font-size: inherit;
  height: 22px;
  line-height: 22px;
  padding: 0px 4px;
  display: inline-block;
}
.cell-tag:focus,
.tags-input input:focus,
.tags-input button:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.cell-tag::-moz-placeholder,
.tags-input input::-moz-placeholder,
.tags-input button::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.cell-tag:-ms-input-placeholder,
.tags-input input:-ms-input-placeholder,
.tags-input button:-ms-input-placeholder {
  color: #999;
}
.cell-tag::-webkit-input-placeholder,
.tags-input input::-webkit-input-placeholder,
.tags-input button::-webkit-input-placeholder {
  color: #999;
}
.cell-tag::-ms-expand,
.tags-input input::-ms-expand,
.tags-input button::-ms-expand {
  border: 0;
  background-color: transparent;
}
.cell-tag[disabled],
.tags-input input[disabled],
.tags-input button[disabled],
.cell-tag[readonly],
.tags-input input[readonly],
.tags-input button[readonly],
fieldset[disabled] .cell-tag,
fieldset[disabled] .tags-input input,
fieldset[disabled] .tags-input button {
  background-color: #eeeeee;
  opacity: 1;
}
.cell-tag[disabled],
.tags-input input[disabled],
.tags-input button[disabled],
fieldset[disabled] .cell-tag,
fieldset[disabled] .tags-input input,
fieldset[disabled] .tags-input button {
  cursor: not-allowed;
}
textarea.cell-tag,
textarea.tags-input input,
textarea.tags-input button {
  height: auto;
}
select.cell-tag,
select.tags-input input,
select.tags-input button {
  height: 30px;
  line-height: 30px;
}
textarea.cell-tag,
textarea.tags-input input,
textarea.tags-input button,
select[multiple].cell-tag,
select[multiple].tags-input input,
select[multiple].tags-input button {
  height: auto;
}
.cell-tag,
.tags-input button {
  padding: 0px 4px;
}
.cell-tag {
  background-color: #fff;
  white-space: nowrap;
}
.tags-input input[type=text]:focus {
  outline: none;
  box-shadow: none;
  border-color: #ccc;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
[dir="rtl"] #kernel_logo_widget {
  float: left !important;
  float: left;
}
.modal .modal-body .move-path {
  display: flex;
  flex-direction: row;
  justify-content: space;
  align-items: center;
}
.modal .modal-body .move-path .server-root {
  padding-right: 20px;
}
.modal .modal-body .move-path .path-input {
  flex: 1;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
[dir="rtl"] #menubar .navbar-toggle {
  float: right;
}
[dir="rtl"] #menubar .navbar-collapse {
  clear: right;
}
[dir="rtl"] #menubar .navbar-nav {
  float: right;
}
[dir="rtl"] #menubar .nav {
  padding-right: 0px;
}
[dir="rtl"] #menubar .navbar-nav > li {
  float: right;
}
[dir="rtl"] #menubar .navbar-right {
  float: left !important;
}
[dir="rtl"] ul.dropdown-menu {
  text-align: right;
  left: auto;
}
[dir="rtl"] ul#new-menu.dropdown-menu {
  right: auto;
  left: 0;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
[dir="rtl"] i.menu-icon.pull-right {
  float: left !important;
  float: left;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
[dir="rtl"] ul#help_menu li a {
  padding-left: 2.2em;
}
[dir="rtl"] ul#help_menu li a i {
  margin-right: 0;
  margin-left: -1.2em;
}
[dir="rtl"] ul#help_menu li a i.pull-right {
  float: left !important;
  float: left;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
[dir="rtl"] .dropdown-submenu > .dropdown-menu {
  right: 100%;
  margin-right: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.fa-pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.fa-pull-right {
  margin-left: .3em;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
[dir="rtl"] .dropdown-submenu > a:after {
  float: left;
  content: "\f0d9";
  margin-right: 0;
  margin-left: -10px;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
[dir="rtl"] #notification_area {
  float: left !important;
  float: left;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
[dir="rtl"] .indicator_area {
  float: left !important;
  float: left;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
[dir="rtl"] #kernel_indicator {
  float: left !important;
  float: left;
  border-left: 0;
  border-right: 1px solid;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
[dir="rtl"] #modal_indicator {
  float: left !important;
  float: left;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.fa-pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.fa-pull-right {
  margin-left: .3em;
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.fa-pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.fa-pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  height: 30px;
  margin-top: 4px;
  display: flex;
  justify-content: flex-start;
  align-items: baseline;
  width: 50%;
  flex: 1;
}
span.save_widget span.filename {
  height: 100%;
  line-height: 1em;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  text-overflow: ellipsis;
  overflow: hidden;
  white-space: nowrap;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
[dir="rtl"] span.save_widget.pull-left {
  float: right !important;
  float: right;
}
[dir="rtl"] span.save_widget span.filename {
  margin-left: 0;
  margin-right: 16px;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
  white-space: nowrap;
  padding: 0 5px;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
    padding: 0 0 0 5px;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
.toolbar-btn-label {
  margin-left: 6px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
[dir="rtl"] .btn-group > .btn,
.btn-group-vertical > .btn {
  float: right;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
[dir="rtl"] ul.typeahead-list i {
  margin-left: 0;
  margin-right: -10px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
ul.typeahead-list  > li > a.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .typeahead-list {
  text-align: right;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  min-width: 20px;
  color: transparent;
}
[dir="rtl"] .no-shortcut.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .command-shortcut.pull-right {
  float: left !important;
  float: left;
}
.command-shortcut:before {
  content: "(command mode)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
[dir="rtl"] .edit-shortcut.pull-right {
  float: left !important;
  float: left;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
[dir="ltr"] #find-and-replace .input-group-btn + .form-control {
  border-left: none;
}
[dir="rtl"] #find-and-replace .input-group-btn + .form-control {
  border-right: none;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span>  <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">drive</span>
<span class="n">drive</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span><span class="s1">&#39;/content/drive&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Mounted at /content/drive
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">data_train</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span> <span class="p">(</span><span class="s2">&quot;/content/drive/MyDrive/AI CAPSTONE PROJECT/Financial/train_data.csv&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">data_train</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">

  <div id="df-f531fff7-5734-4920-9a1f-a72fe4ed1a2f">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Time</th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>V10</th>
      <th>V11</th>
      <th>V12</th>
      <th>V13</th>
      <th>V14</th>
      <th>V15</th>
      <th>V16</th>
      <th>V17</th>
      <th>V18</th>
      <th>V19</th>
      <th>V20</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Amount</th>
      <th>Class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>38355.0</td>
      <td>1.043949</td>
      <td>0.318555</td>
      <td>1.045810</td>
      <td>2.805989</td>
      <td>-0.561113</td>
      <td>-0.367956</td>
      <td>0.032736</td>
      <td>-0.042333</td>
      <td>-0.322674</td>
      <td>0.499167</td>
      <td>-0.572665</td>
      <td>0.346009</td>
      <td>-0.047407</td>
      <td>-0.098964</td>
      <td>-0.663284</td>
      <td>0.181411</td>
      <td>-0.124345</td>
      <td>-0.790453</td>
      <td>-0.720944</td>
      <td>-0.084556</td>
      <td>-0.240105</td>
      <td>-0.680315</td>
      <td>0.085328</td>
      <td>0.684812</td>
      <td>0.318620</td>
      <td>-0.204963</td>
      <td>0.001662</td>
      <td>0.037894</td>
      <td>49.67</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>22555.0</td>
      <td>-1.665159</td>
      <td>0.808440</td>
      <td>1.805627</td>
      <td>1.903416</td>
      <td>-0.821627</td>
      <td>0.934790</td>
      <td>-0.824802</td>
      <td>0.975890</td>
      <td>1.747469</td>
      <td>-0.658751</td>
      <td>1.281502</td>
      <td>-1.430087</td>
      <td>0.372028</td>
      <td>1.403024</td>
      <td>-2.739413</td>
      <td>-1.331766</td>
      <td>1.964590</td>
      <td>-0.205639</td>
      <td>1.325588</td>
      <td>-0.373759</td>
      <td>-0.335332</td>
      <td>-0.510994</td>
      <td>0.035839</td>
      <td>0.147565</td>
      <td>-0.529358</td>
      <td>-0.566950</td>
      <td>-0.595998</td>
      <td>-0.220086</td>
      <td>16.94</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2431.0</td>
      <td>-0.324096</td>
      <td>0.601836</td>
      <td>0.865329</td>
      <td>-2.138000</td>
      <td>0.294663</td>
      <td>-1.251553</td>
      <td>1.072114</td>
      <td>-0.334896</td>
      <td>1.071268</td>
      <td>-1.109522</td>
      <td>-1.016020</td>
      <td>-0.654945</td>
      <td>-1.473470</td>
      <td>0.317345</td>
      <td>1.067491</td>
      <td>-0.372642</td>
      <td>-0.674725</td>
      <td>0.369841</td>
      <td>0.095583</td>
      <td>-0.039868</td>
      <td>0.012220</td>
      <td>0.352856</td>
      <td>-0.341505</td>
      <td>-0.145791</td>
      <td>0.094194</td>
      <td>-0.804026</td>
      <td>0.229428</td>
      <td>-0.021623</td>
      <td>1.00</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>86773.0</td>
      <td>-0.258270</td>
      <td>1.217501</td>
      <td>-0.585348</td>
      <td>-0.875347</td>
      <td>1.222481</td>
      <td>-0.311027</td>
      <td>1.073860</td>
      <td>-0.161408</td>
      <td>0.200665</td>
      <td>0.154307</td>
      <td>0.882673</td>
      <td>0.547890</td>
      <td>0.269484</td>
      <td>-1.253302</td>
      <td>-0.883963</td>
      <td>0.495221</td>
      <td>-0.153212</td>
      <td>0.296710</td>
      <td>0.136148</td>
      <td>0.382305</td>
      <td>-0.424626</td>
      <td>-0.781158</td>
      <td>0.019316</td>
      <td>0.178614</td>
      <td>-0.315616</td>
      <td>0.096665</td>
      <td>0.269740</td>
      <td>-0.020635</td>
      <td>10.78</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>127202.0</td>
      <td>2.142162</td>
      <td>-0.494988</td>
      <td>-1.936511</td>
      <td>-0.818288</td>
      <td>-0.025213</td>
      <td>-1.027245</td>
      <td>-0.151627</td>
      <td>-0.305750</td>
      <td>-0.869482</td>
      <td>0.428729</td>
      <td>1.136666</td>
      <td>0.273476</td>
      <td>0.697123</td>
      <td>-1.222134</td>
      <td>-0.938820</td>
      <td>1.298149</td>
      <td>0.912921</td>
      <td>-0.793721</td>
      <td>1.064984</td>
      <td>0.106592</td>
      <td>0.010115</td>
      <td>0.021722</td>
      <td>0.079463</td>
      <td>-0.480899</td>
      <td>0.023846</td>
      <td>-0.279076</td>
      <td>-0.030121</td>
      <td>-0.043888</td>
      <td>39.96</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-f531fff7-5734-4920-9a1f-a72fe4ed1a2f')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-f531fff7-5734-4920-9a1f-a72fe4ed1a2f button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-f531fff7-5734-4920-9a1f-a72fe4ed1a2f');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">data_test</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;/content/drive/MyDrive/AI CAPSTONE PROJECT/Financial/test_data.csv&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">data_test_hidden</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;/content/drive/MyDrive/AI CAPSTONE PROJECT/Financial/test_data_hidden.csv&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">data_test</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span><span class="n">data_test_hidden</span><span class="o">.</span><span class="n">columns</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(Index([&#39;Time&#39;, &#39;V1&#39;, &#39;V2&#39;, &#39;V3&#39;, &#39;V4&#39;, &#39;V5&#39;, &#39;V6&#39;, &#39;V7&#39;, &#39;V8&#39;, &#39;V9&#39;, &#39;V10&#39;,
        &#39;V11&#39;, &#39;V12&#39;, &#39;V13&#39;, &#39;V14&#39;, &#39;V15&#39;, &#39;V16&#39;, &#39;V17&#39;, &#39;V18&#39;, &#39;V19&#39;, &#39;V20&#39;,
        &#39;V21&#39;, &#39;V22&#39;, &#39;V23&#39;, &#39;V24&#39;, &#39;V25&#39;, &#39;V26&#39;, &#39;V27&#39;, &#39;V28&#39;, &#39;Amount&#39;],
       dtype=&#39;object&#39;),
 Index([&#39;Time&#39;, &#39;V1&#39;, &#39;V2&#39;, &#39;V3&#39;, &#39;V4&#39;, &#39;V5&#39;, &#39;V6&#39;, &#39;V7&#39;, &#39;V8&#39;, &#39;V9&#39;, &#39;V10&#39;,
        &#39;V11&#39;, &#39;V12&#39;, &#39;V13&#39;, &#39;V14&#39;, &#39;V15&#39;, &#39;V16&#39;, &#39;V17&#39;, &#39;V18&#39;, &#39;V19&#39;, &#39;V20&#39;,
        &#39;V21&#39;, &#39;V22&#39;, &#39;V23&#39;, &#39;V24&#39;, &#39;V25&#39;, &#39;V26&#39;, &#39;V27&#39;, &#39;V28&#39;, &#39;Amount&#39;,
        &#39;Class&#39;],
       dtype=&#39;object&#39;))</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">data_test</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">

  <div id="df-cb6b2ee7-0f54-4701-92e7-d333d86b589c">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Time</th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>V10</th>
      <th>V11</th>
      <th>V12</th>
      <th>V13</th>
      <th>V14</th>
      <th>V15</th>
      <th>V16</th>
      <th>V17</th>
      <th>V18</th>
      <th>V19</th>
      <th>V20</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Amount</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>113050.0</td>
      <td>0.114697</td>
      <td>0.796303</td>
      <td>-0.149553</td>
      <td>-0.823011</td>
      <td>0.878763</td>
      <td>-0.553152</td>
      <td>0.939259</td>
      <td>-0.108502</td>
      <td>0.111137</td>
      <td>-0.390521</td>
      <td>-1.949546</td>
      <td>-0.494436</td>
      <td>-0.353696</td>
      <td>0.158729</td>
      <td>-0.267239</td>
      <td>0.234802</td>
      <td>-0.754936</td>
      <td>-0.343012</td>
      <td>0.312175</td>
      <td>-0.042711</td>
      <td>-0.335776</td>
      <td>-0.807853</td>
      <td>-0.055940</td>
      <td>-1.025281</td>
      <td>-0.369557</td>
      <td>0.204653</td>
      <td>0.242724</td>
      <td>0.085713</td>
      <td>0.89</td>
    </tr>
    <tr>
      <th>1</th>
      <td>26667.0</td>
      <td>-0.039318</td>
      <td>0.495784</td>
      <td>-0.810884</td>
      <td>0.546693</td>
      <td>1.986257</td>
      <td>4.386342</td>
      <td>-1.344891</td>
      <td>-1.743736</td>
      <td>-0.563103</td>
      <td>-0.616315</td>
      <td>-0.587786</td>
      <td>0.317419</td>
      <td>-0.408521</td>
      <td>0.719639</td>
      <td>0.226926</td>
      <td>-0.296316</td>
      <td>-0.040143</td>
      <td>0.119177</td>
      <td>1.057682</td>
      <td>0.926255</td>
      <td>-1.377003</td>
      <td>-0.072200</td>
      <td>-0.197573</td>
      <td>1.014807</td>
      <td>1.011293</td>
      <td>-0.167684</td>
      <td>0.113136</td>
      <td>0.256836</td>
      <td>85.00</td>
    </tr>
    <tr>
      <th>2</th>
      <td>159519.0</td>
      <td>2.275706</td>
      <td>-1.531508</td>
      <td>-1.021969</td>
      <td>-1.602152</td>
      <td>-1.220329</td>
      <td>-0.462376</td>
      <td>-1.196485</td>
      <td>-0.147058</td>
      <td>-0.950224</td>
      <td>1.560463</td>
      <td>-1.753256</td>
      <td>-1.331010</td>
      <td>-0.061941</td>
      <td>-0.405532</td>
      <td>0.048083</td>
      <td>-0.307503</td>
      <td>0.289363</td>
      <td>0.189739</td>
      <td>0.022546</td>
      <td>-0.408289</td>
      <td>-0.193271</td>
      <td>-0.103533</td>
      <td>0.150945</td>
      <td>-0.811083</td>
      <td>-0.197913</td>
      <td>-0.128446</td>
      <td>0.014197</td>
      <td>-0.051289</td>
      <td>42.70</td>
    </tr>
    <tr>
      <th>3</th>
      <td>137545.0</td>
      <td>1.940137</td>
      <td>-0.357671</td>
      <td>-1.210551</td>
      <td>0.382523</td>
      <td>0.050823</td>
      <td>-0.171322</td>
      <td>-0.109124</td>
      <td>-0.002115</td>
      <td>0.869258</td>
      <td>-0.001965</td>
      <td>0.607629</td>
      <td>1.048673</td>
      <td>-0.514821</td>
      <td>0.329538</td>
      <td>-1.041463</td>
      <td>-0.498797</td>
      <td>-0.276887</td>
      <td>0.114245</td>
      <td>0.379447</td>
      <td>-0.199280</td>
      <td>0.157994</td>
      <td>0.650355</td>
      <td>0.034206</td>
      <td>0.739535</td>
      <td>0.223605</td>
      <td>-0.195509</td>
      <td>-0.012791</td>
      <td>-0.056841</td>
      <td>29.99</td>
    </tr>
    <tr>
      <th>4</th>
      <td>63369.0</td>
      <td>1.081395</td>
      <td>-0.502615</td>
      <td>1.075887</td>
      <td>-0.543359</td>
      <td>-1.472946</td>
      <td>-1.065484</td>
      <td>-0.443231</td>
      <td>-0.143374</td>
      <td>1.659826</td>
      <td>-1.131238</td>
      <td>0.173132</td>
      <td>1.430172</td>
      <td>0.915609</td>
      <td>-0.336588</td>
      <td>1.140171</td>
      <td>-0.653626</td>
      <td>-0.016567</td>
      <td>0.066287</td>
      <td>0.242537</td>
      <td>0.059880</td>
      <td>0.224157</td>
      <td>0.821209</td>
      <td>-0.137223</td>
      <td>0.986259</td>
      <td>0.563228</td>
      <td>-0.574206</td>
      <td>0.089673</td>
      <td>0.052036</td>
      <td>68.00</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-cb6b2ee7-0f54-4701-92e7-d333d86b589c')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-cb6b2ee7-0f54-4701-92e7-d333d86b589c button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-cb6b2ee7-0f54-4701-92e7-d333d86b589c');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">data_test_hidden</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">

  <div id="df-802f2fa4-4ddf-46ec-bd70-210aa6ab0737">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Time</th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>V10</th>
      <th>V11</th>
      <th>V12</th>
      <th>V13</th>
      <th>V14</th>
      <th>V15</th>
      <th>V16</th>
      <th>V17</th>
      <th>V18</th>
      <th>V19</th>
      <th>V20</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Amount</th>
      <th>Class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>113050.0</td>
      <td>0.114697</td>
      <td>0.796303</td>
      <td>-0.149553</td>
      <td>-0.823011</td>
      <td>0.878763</td>
      <td>-0.553152</td>
      <td>0.939259</td>
      <td>-0.108502</td>
      <td>0.111137</td>
      <td>-0.390521</td>
      <td>-1.949546</td>
      <td>-0.494436</td>
      <td>-0.353696</td>
      <td>0.158729</td>
      <td>-0.267239</td>
      <td>0.234802</td>
      <td>-0.754936</td>
      <td>-0.343012</td>
      <td>0.312175</td>
      <td>-0.042711</td>
      <td>-0.335776</td>
      <td>-0.807853</td>
      <td>-0.055940</td>
      <td>-1.025281</td>
      <td>-0.369557</td>
      <td>0.204653</td>
      <td>0.242724</td>
      <td>0.085713</td>
      <td>0.89</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>26667.0</td>
      <td>-0.039318</td>
      <td>0.495784</td>
      <td>-0.810884</td>
      <td>0.546693</td>
      <td>1.986257</td>
      <td>4.386342</td>
      <td>-1.344891</td>
      <td>-1.743736</td>
      <td>-0.563103</td>
      <td>-0.616315</td>
      <td>-0.587786</td>
      <td>0.317419</td>
      <td>-0.408521</td>
      <td>0.719639</td>
      <td>0.226926</td>
      <td>-0.296316</td>
      <td>-0.040143</td>
      <td>0.119177</td>
      <td>1.057682</td>
      <td>0.926255</td>
      <td>-1.377003</td>
      <td>-0.072200</td>
      <td>-0.197573</td>
      <td>1.014807</td>
      <td>1.011293</td>
      <td>-0.167684</td>
      <td>0.113136</td>
      <td>0.256836</td>
      <td>85.00</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>159519.0</td>
      <td>2.275706</td>
      <td>-1.531508</td>
      <td>-1.021969</td>
      <td>-1.602152</td>
      <td>-1.220329</td>
      <td>-0.462376</td>
      <td>-1.196485</td>
      <td>-0.147058</td>
      <td>-0.950224</td>
      <td>1.560463</td>
      <td>-1.753256</td>
      <td>-1.331010</td>
      <td>-0.061941</td>
      <td>-0.405532</td>
      <td>0.048083</td>
      <td>-0.307503</td>
      <td>0.289363</td>
      <td>0.189739</td>
      <td>0.022546</td>
      <td>-0.408289</td>
      <td>-0.193271</td>
      <td>-0.103533</td>
      <td>0.150945</td>
      <td>-0.811083</td>
      <td>-0.197913</td>
      <td>-0.128446</td>
      <td>0.014197</td>
      <td>-0.051289</td>
      <td>42.70</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>137545.0</td>
      <td>1.940137</td>
      <td>-0.357671</td>
      <td>-1.210551</td>
      <td>0.382523</td>
      <td>0.050823</td>
      <td>-0.171322</td>
      <td>-0.109124</td>
      <td>-0.002115</td>
      <td>0.869258</td>
      <td>-0.001965</td>
      <td>0.607629</td>
      <td>1.048673</td>
      <td>-0.514821</td>
      <td>0.329538</td>
      <td>-1.041463</td>
      <td>-0.498797</td>
      <td>-0.276887</td>
      <td>0.114245</td>
      <td>0.379447</td>
      <td>-0.199280</td>
      <td>0.157994</td>
      <td>0.650355</td>
      <td>0.034206</td>
      <td>0.739535</td>
      <td>0.223605</td>
      <td>-0.195509</td>
      <td>-0.012791</td>
      <td>-0.056841</td>
      <td>29.99</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>63369.0</td>
      <td>1.081395</td>
      <td>-0.502615</td>
      <td>1.075887</td>
      <td>-0.543359</td>
      <td>-1.472946</td>
      <td>-1.065484</td>
      <td>-0.443231</td>
      <td>-0.143374</td>
      <td>1.659826</td>
      <td>-1.131238</td>
      <td>0.173132</td>
      <td>1.430172</td>
      <td>0.915609</td>
      <td>-0.336588</td>
      <td>1.140171</td>
      <td>-0.653626</td>
      <td>-0.016567</td>
      <td>0.066287</td>
      <td>0.242537</td>
      <td>0.059880</td>
      <td>0.224157</td>
      <td>0.821209</td>
      <td>-0.137223</td>
      <td>0.986259</td>
      <td>0.563228</td>
      <td>-0.574206</td>
      <td>0.089673</td>
      <td>0.052036</td>
      <td>68.00</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-802f2fa4-4ddf-46ec-bd70-210aa6ab0737')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-802f2fa4-4ddf-46ec-bd70-210aa6ab0737 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-802f2fa4-4ddf-46ec-bd70-210aa6ab0737');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">data_train</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span><span class="n">data_test</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(Time           2
 V1             0
 V2             0
 V3             0
 V4             0
 V5             0
 V6             0
 V7             0
 V8             0
 V9             0
 V10            0
 V11            0
 V12            0
 V13            0
 V14            0
 V15            0
 V16            0
 V17            0
 V18            0
 V19            0
 V20            0
 V21            0
 V22            0
 V23            0
 V24            0
 V25            0
 V26            0
 V27            0
 V28            0
 Amount      1467
 Class     227451
 dtype: int64, Time        0
 V1          0
 V2          0
 V3          0
 V4          0
 V5          0
 V6          0
 V7          0
 V8          0
 V9          0
 V10         0
 V11         0
 V12         0
 V13         0
 V14         0
 V15         0
 V16         0
 V17         0
 V18         0
 V19         0
 V20         0
 V21         0
 V22         0
 V23         0
 V24         0
 V25         0
 V26         0
 V27         0
 V28         0
 Amount    358
 dtype: int64)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Checking the shape of the three datasets provided</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">data_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span><span class="n">data_test</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span><span class="n">data_test_hidden</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>((227845, 31), (56962, 30), (56962, 31))</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">data_train</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">

  <div id="df-ed73ce31-6912-4b2c-b018-8e21e7f01d40">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Time</th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>V10</th>
      <th>V11</th>
      <th>V12</th>
      <th>V13</th>
      <th>V14</th>
      <th>V15</th>
      <th>V16</th>
      <th>V17</th>
      <th>V18</th>
      <th>V19</th>
      <th>V20</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Amount</th>
      <th>Class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Time</th>
      <td>1.000000</td>
      <td>0.117777</td>
      <td>-0.010475</td>
      <td>-0.419784</td>
      <td>-0.105047</td>
      <td>0.173334</td>
      <td>-0.063703</td>
      <td>0.084606</td>
      <td>-0.036989</td>
      <td>-0.009281</td>
      <td>0.030671</td>
      <td>-0.249075</td>
      <td>0.124282</td>
      <td>-0.066625</td>
      <td>-0.098673</td>
      <td>-0.183040</td>
      <td>0.011148</td>
      <td>-0.073465</td>
      <td>0.092087</td>
      <td>0.028649</td>
      <td>-0.051160</td>
      <td>0.044253</td>
      <td>0.144670</td>
      <td>0.049683</td>
      <td>-0.015547</td>
      <td>-0.231976</td>
      <td>-0.040369</td>
      <td>-0.005736</td>
      <td>-0.009289</td>
      <td>-0.011328</td>
      <td>-0.012800</td>
    </tr>
    <tr>
      <th>V1</th>
      <td>0.117777</td>
      <td>1.000000</td>
      <td>0.008229</td>
      <td>0.001239</td>
      <td>-0.002554</td>
      <td>-0.003554</td>
      <td>0.003348</td>
      <td>0.002552</td>
      <td>-0.001899</td>
      <td>0.001410</td>
      <td>0.001575</td>
      <td>-0.000925</td>
      <td>-0.001735</td>
      <td>-0.000463</td>
      <td>-0.001540</td>
      <td>-0.000989</td>
      <td>-0.002626</td>
      <td>-0.000568</td>
      <td>0.000267</td>
      <td>0.000583</td>
      <td>-0.002032</td>
      <td>-0.001978</td>
      <td>0.002074</td>
      <td>0.010848</td>
      <td>-0.001089</td>
      <td>0.003159</td>
      <td>0.002461</td>
      <td>0.014184</td>
      <td>-0.013830</td>
      <td>-0.228808</td>
      <td>-0.103095</td>
    </tr>
    <tr>
      <th>V2</th>
      <td>-0.010475</td>
      <td>0.008229</td>
      <td>1.000000</td>
      <td>0.003076</td>
      <td>-0.001860</td>
      <td>-0.004229</td>
      <td>0.001530</td>
      <td>0.001980</td>
      <td>-0.000321</td>
      <td>-0.002448</td>
      <td>-0.004113</td>
      <td>-0.000226</td>
      <td>-0.001595</td>
      <td>-0.001058</td>
      <td>-0.000624</td>
      <td>-0.000925</td>
      <td>-0.002382</td>
      <td>-0.001191</td>
      <td>0.001879</td>
      <td>0.002284</td>
      <td>-0.009700</td>
      <td>-0.003032</td>
      <td>0.004273</td>
      <td>0.007231</td>
      <td>0.002603</td>
      <td>0.003127</td>
      <td>0.002701</td>
      <td>0.013555</td>
      <td>-0.015893</td>
      <td>-0.537855</td>
      <td>0.093795</td>
    </tr>
    <tr>
      <th>V3</th>
      <td>-0.419784</td>
      <td>0.001239</td>
      <td>0.003076</td>
      <td>1.000000</td>
      <td>-0.001147</td>
      <td>-0.005848</td>
      <td>0.004419</td>
      <td>0.007959</td>
      <td>0.000722</td>
      <td>0.000356</td>
      <td>0.000990</td>
      <td>0.001510</td>
      <td>-0.000445</td>
      <td>-0.000625</td>
      <td>-0.002743</td>
      <td>0.001516</td>
      <td>0.001657</td>
      <td>-0.000760</td>
      <td>0.001047</td>
      <td>0.001547</td>
      <td>-0.006893</td>
      <td>-0.002979</td>
      <td>0.001248</td>
      <td>0.008481</td>
      <td>-0.000150</td>
      <td>0.003749</td>
      <td>0.001626</td>
      <td>0.013268</td>
      <td>-0.009067</td>
      <td>-0.207587</td>
      <td>-0.196385</td>
    </tr>
    <tr>
      <th>V4</th>
      <td>-0.105047</td>
      <td>-0.002554</td>
      <td>-0.001860</td>
      <td>-0.001147</td>
      <td>1.000000</td>
      <td>0.001981</td>
      <td>-0.003068</td>
      <td>-0.003616</td>
      <td>-0.001397</td>
      <td>0.000070</td>
      <td>0.001005</td>
      <td>0.003250</td>
      <td>0.001564</td>
      <td>-0.000548</td>
      <td>0.001915</td>
      <td>-0.001500</td>
      <td>-0.001814</td>
      <td>-0.001052</td>
      <td>0.001431</td>
      <td>-0.001817</td>
      <td>0.003787</td>
      <td>0.003349</td>
      <td>-0.002147</td>
      <td>-0.001533</td>
      <td>-0.001154</td>
      <td>-0.000707</td>
      <td>-0.000590</td>
      <td>-0.007427</td>
      <td>0.004131</td>
      <td>0.098695</td>
      <td>0.134044</td>
    </tr>
    <tr>
      <th>V5</th>
      <td>0.173334</td>
      <td>-0.003554</td>
      <td>-0.004229</td>
      <td>-0.005848</td>
      <td>0.001981</td>
      <td>1.000000</td>
      <td>0.014932</td>
      <td>0.025536</td>
      <td>-0.004610</td>
      <td>-0.000297</td>
      <td>-0.003156</td>
      <td>0.001762</td>
      <td>-0.003938</td>
      <td>0.001445</td>
      <td>-0.001382</td>
      <td>0.002530</td>
      <td>0.003845</td>
      <td>-0.002759</td>
      <td>0.000495</td>
      <td>0.001780</td>
      <td>-0.016817</td>
      <td>-0.008510</td>
      <td>0.002784</td>
      <td>0.007772</td>
      <td>0.000823</td>
      <td>0.004833</td>
      <td>0.002322</td>
      <td>0.022597</td>
      <td>-0.010706</td>
      <td>-0.367801</td>
      <td>-0.099712</td>
    </tr>
    <tr>
      <th>V6</th>
      <td>-0.063703</td>
      <td>0.003348</td>
      <td>0.001530</td>
      <td>0.004419</td>
      <td>-0.003068</td>
      <td>0.014932</td>
      <td>1.000000</td>
      <td>-0.017351</td>
      <td>0.004478</td>
      <td>0.000179</td>
      <td>0.001427</td>
      <td>-0.000244</td>
      <td>0.000958</td>
      <td>-0.000971</td>
      <td>0.002442</td>
      <td>-0.002707</td>
      <td>-0.004873</td>
      <td>-0.000066</td>
      <td>-0.000894</td>
      <td>-0.000916</td>
      <td>0.011611</td>
      <td>0.005147</td>
      <td>-0.002171</td>
      <td>-0.003562</td>
      <td>-0.001478</td>
      <td>-0.002102</td>
      <td>-0.002203</td>
      <td>-0.012878</td>
      <td>0.008897</td>
      <td>0.201285</td>
      <td>-0.042548</td>
    </tr>
    <tr>
      <th>V7</th>
      <td>0.084606</td>
      <td>0.002552</td>
      <td>0.001980</td>
      <td>0.007959</td>
      <td>-0.003616</td>
      <td>0.025536</td>
      <td>-0.017351</td>
      <td>1.000000</td>
      <td>0.007750</td>
      <td>0.003864</td>
      <td>0.007053</td>
      <td>-0.000213</td>
      <td>0.006388</td>
      <td>-0.001361</td>
      <td>0.002486</td>
      <td>-0.002471</td>
      <td>-0.003515</td>
      <td>0.005135</td>
      <td>0.002213</td>
      <td>-0.003600</td>
      <td>0.021419</td>
      <td>0.009986</td>
      <td>-0.003077</td>
      <td>-0.008366</td>
      <td>-0.002986</td>
      <td>-0.003375</td>
      <td>-0.004025</td>
      <td>-0.025285</td>
      <td>0.017643</td>
      <td>0.377417</td>
      <td>-0.196860</td>
    </tr>
    <tr>
      <th>V8</th>
      <td>-0.036989</td>
      <td>-0.001899</td>
      <td>-0.000321</td>
      <td>0.000722</td>
      <td>-0.001397</td>
      <td>-0.004610</td>
      <td>0.004478</td>
      <td>0.007750</td>
      <td>1.000000</td>
      <td>-0.000134</td>
      <td>0.002166</td>
      <td>-0.002407</td>
      <td>0.003678</td>
      <td>0.002506</td>
      <td>0.004858</td>
      <td>0.001618</td>
      <td>0.004699</td>
      <td>0.005369</td>
      <td>0.003033</td>
      <td>-0.000373</td>
      <td>-0.005609</td>
      <td>-0.000250</td>
      <td>-0.001087</td>
      <td>0.005675</td>
      <td>0.001012</td>
      <td>0.002866</td>
      <td>0.001722</td>
      <td>0.006867</td>
      <td>-0.009391</td>
      <td>-0.097939</td>
      <td>0.013376</td>
    </tr>
    <tr>
      <th>V9</th>
      <td>-0.009281</td>
      <td>0.001410</td>
      <td>-0.002448</td>
      <td>0.000356</td>
      <td>0.000070</td>
      <td>-0.000297</td>
      <td>0.000179</td>
      <td>0.003864</td>
      <td>-0.000134</td>
      <td>1.000000</td>
      <td>-0.000698</td>
      <td>0.001382</td>
      <td>0.000656</td>
      <td>0.001798</td>
      <td>0.000575</td>
      <td>0.002350</td>
      <td>0.001387</td>
      <td>0.002512</td>
      <td>0.001363</td>
      <td>0.001724</td>
      <td>-0.005520</td>
      <td>-0.001672</td>
      <td>-0.001095</td>
      <td>-0.002803</td>
      <td>0.000655</td>
      <td>-0.001328</td>
      <td>0.000409</td>
      <td>0.000861</td>
      <td>0.003987</td>
      <td>-0.044312</td>
      <td>-0.099674</td>
    </tr>
    <tr>
      <th>V10</th>
      <td>0.030671</td>
      <td>0.001575</td>
      <td>-0.004113</td>
      <td>0.000990</td>
      <td>0.001005</td>
      <td>-0.003156</td>
      <td>0.001427</td>
      <td>0.007053</td>
      <td>0.002166</td>
      <td>-0.000698</td>
      <td>1.000000</td>
      <td>-0.000331</td>
      <td>0.001386</td>
      <td>-0.001339</td>
      <td>-0.000151</td>
      <td>0.000386</td>
      <td>0.003860</td>
      <td>0.002205</td>
      <td>0.001675</td>
      <td>0.001178</td>
      <td>-0.006727</td>
      <td>-0.003130</td>
      <td>0.000088</td>
      <td>-0.000647</td>
      <td>0.000737</td>
      <td>-0.000054</td>
      <td>0.001100</td>
      <td>0.003633</td>
      <td>0.001012</td>
      <td>-0.099188</td>
      <td>-0.222186</td>
    </tr>
    <tr>
      <th>V11</th>
      <td>-0.249075</td>
      <td>-0.000925</td>
      <td>-0.000226</td>
      <td>0.001510</td>
      <td>0.003250</td>
      <td>0.001762</td>
      <td>-0.000244</td>
      <td>-0.000213</td>
      <td>-0.002407</td>
      <td>0.001382</td>
      <td>-0.000331</td>
      <td>1.000000</td>
      <td>-0.000699</td>
      <td>-0.000167</td>
      <td>0.001096</td>
      <td>0.001853</td>
      <td>-0.000200</td>
      <td>0.000460</td>
      <td>-0.002124</td>
      <td>0.000977</td>
      <td>0.000344</td>
      <td>0.000816</td>
      <td>0.000030</td>
      <td>0.002191</td>
      <td>-0.000692</td>
      <td>-0.001255</td>
      <td>0.000354</td>
      <td>-0.003505</td>
      <td>0.003802</td>
      <td>-0.001032</td>
      <td>0.156553</td>
    </tr>
    <tr>
      <th>V12</th>
      <td>0.124282</td>
      <td>-0.001735</td>
      <td>-0.001595</td>
      <td>-0.000445</td>
      <td>0.001564</td>
      <td>-0.003938</td>
      <td>0.000958</td>
      <td>0.006388</td>
      <td>0.003678</td>
      <td>0.000656</td>
      <td>0.001386</td>
      <td>-0.000699</td>
      <td>1.000000</td>
      <td>-0.000614</td>
      <td>-0.000278</td>
      <td>0.000431</td>
      <td>-0.000053</td>
      <td>-0.000741</td>
      <td>0.000238</td>
      <td>-0.000173</td>
      <td>-0.004597</td>
      <td>-0.000582</td>
      <td>-0.000502</td>
      <td>0.000464</td>
      <td>0.000243</td>
      <td>0.000539</td>
      <td>0.001393</td>
      <td>0.003483</td>
      <td>-0.001420</td>
      <td>-0.005946</td>
      <td>-0.262903</td>
    </tr>
    <tr>
      <th>V13</th>
      <td>-0.066625</td>
      <td>-0.000463</td>
      <td>-0.001058</td>
      <td>-0.000625</td>
      <td>-0.000548</td>
      <td>0.001445</td>
      <td>-0.000971</td>
      <td>-0.001361</td>
      <td>0.002506</td>
      <td>0.001798</td>
      <td>-0.001339</td>
      <td>-0.000167</td>
      <td>-0.000614</td>
      <td>1.000000</td>
      <td>0.000348</td>
      <td>0.002084</td>
      <td>0.000172</td>
      <td>0.000592</td>
      <td>0.001104</td>
      <td>-0.002623</td>
      <td>0.001111</td>
      <td>0.000272</td>
      <td>0.000276</td>
      <td>-0.001214</td>
      <td>0.000381</td>
      <td>-0.001991</td>
      <td>-0.001184</td>
      <td>-0.004479</td>
      <td>0.001209</td>
      <td>0.004013</td>
      <td>-0.003179</td>
    </tr>
    <tr>
      <th>V14</th>
      <td>-0.098673</td>
      <td>-0.001540</td>
      <td>-0.000624</td>
      <td>-0.002743</td>
      <td>0.001915</td>
      <td>-0.001382</td>
      <td>0.002442</td>
      <td>0.002486</td>
      <td>0.004858</td>
      <td>0.000575</td>
      <td>-0.000151</td>
      <td>0.001096</td>
      <td>-0.000278</td>
      <td>0.000348</td>
      <td>1.000000</td>
      <td>0.000613</td>
      <td>0.002461</td>
      <td>0.000771</td>
      <td>0.000206</td>
      <td>-0.002507</td>
      <td>0.001126</td>
      <td>-0.001935</td>
      <td>0.001396</td>
      <td>0.000020</td>
      <td>-0.000841</td>
      <td>0.001875</td>
      <td>-0.001374</td>
      <td>0.001623</td>
      <td>-0.003638</td>
      <td>0.037325</td>
      <td>-0.304232</td>
    </tr>
    <tr>
      <th>V15</th>
      <td>-0.183040</td>
      <td>-0.000989</td>
      <td>-0.000925</td>
      <td>0.001516</td>
      <td>-0.001500</td>
      <td>0.002530</td>
      <td>-0.002707</td>
      <td>-0.002471</td>
      <td>0.001618</td>
      <td>0.002350</td>
      <td>0.000386</td>
      <td>0.001853</td>
      <td>0.000431</td>
      <td>0.002084</td>
      <td>0.000613</td>
      <td>1.000000</td>
      <td>-0.001718</td>
      <td>0.000437</td>
      <td>-0.000865</td>
      <td>-0.000774</td>
      <td>-0.000107</td>
      <td>0.001392</td>
      <td>-0.000730</td>
      <td>-0.001792</td>
      <td>0.001198</td>
      <td>-0.002857</td>
      <td>-0.001119</td>
      <td>-0.003624</td>
      <td>0.005619</td>
      <td>-0.006642</td>
      <td>-0.004350</td>
    </tr>
    <tr>
      <th>V16</th>
      <td>0.011148</td>
      <td>-0.002626</td>
      <td>-0.002382</td>
      <td>0.001657</td>
      <td>-0.001814</td>
      <td>0.003845</td>
      <td>-0.004873</td>
      <td>-0.003515</td>
      <td>0.004699</td>
      <td>0.001387</td>
      <td>0.003860</td>
      <td>-0.000200</td>
      <td>-0.000053</td>
      <td>0.000172</td>
      <td>0.002461</td>
      <td>-0.001718</td>
      <td>1.000000</td>
      <td>0.002626</td>
      <td>0.001034</td>
      <td>0.001762</td>
      <td>0.002739</td>
      <td>0.003097</td>
      <td>-0.002450</td>
      <td>-0.005952</td>
      <td>0.000610</td>
      <td>-0.000658</td>
      <td>-0.001295</td>
      <td>-0.006406</td>
      <td>0.005165</td>
      <td>-0.008466</td>
      <td>-0.201828</td>
    </tr>
    <tr>
      <th>V17</th>
      <td>-0.073465</td>
      <td>-0.000568</td>
      <td>-0.001191</td>
      <td>-0.000760</td>
      <td>-0.001052</td>
      <td>-0.002759</td>
      <td>-0.000066</td>
      <td>0.005135</td>
      <td>0.005369</td>
      <td>0.002512</td>
      <td>0.002205</td>
      <td>0.000460</td>
      <td>-0.000741</td>
      <td>0.000592</td>
      <td>0.000771</td>
      <td>0.000437</td>
      <td>0.002626</td>
      <td>1.000000</td>
      <td>0.000665</td>
      <td>-0.000507</td>
      <td>-0.000987</td>
      <td>0.000445</td>
      <td>-0.000404</td>
      <td>-0.000381</td>
      <td>0.000838</td>
      <td>0.000736</td>
      <td>0.000540</td>
      <td>0.004757</td>
      <td>-0.002350</td>
      <td>0.010491</td>
      <td>-0.333463</td>
    </tr>
    <tr>
      <th>V18</th>
      <td>0.092087</td>
      <td>0.000267</td>
      <td>0.001879</td>
      <td>0.001047</td>
      <td>0.001431</td>
      <td>0.000495</td>
      <td>-0.000894</td>
      <td>0.002213</td>
      <td>0.003033</td>
      <td>0.001363</td>
      <td>0.001675</td>
      <td>-0.002124</td>
      <td>0.000238</td>
      <td>0.001104</td>
      <td>0.000206</td>
      <td>-0.000865</td>
      <td>0.001034</td>
      <td>0.000665</td>
      <td>1.000000</td>
      <td>0.000278</td>
      <td>0.001211</td>
      <td>0.001289</td>
      <td>-0.001111</td>
      <td>0.001496</td>
      <td>0.001445</td>
      <td>0.000802</td>
      <td>-0.000488</td>
      <td>0.002055</td>
      <td>-0.003434</td>
      <td>0.035866</td>
      <td>-0.114699</td>
    </tr>
    <tr>
      <th>V19</th>
      <td>0.028649</td>
      <td>0.000583</td>
      <td>0.002284</td>
      <td>0.001547</td>
      <td>-0.001817</td>
      <td>0.001780</td>
      <td>-0.000916</td>
      <td>-0.003600</td>
      <td>-0.000373</td>
      <td>0.001724</td>
      <td>0.001178</td>
      <td>0.000977</td>
      <td>-0.000173</td>
      <td>-0.002623</td>
      <td>-0.002507</td>
      <td>-0.000774</td>
      <td>0.001762</td>
      <td>-0.000507</td>
      <td>0.000278</td>
      <td>1.000000</td>
      <td>-0.000780</td>
      <td>0.001622</td>
      <td>-0.001137</td>
      <td>-0.001297</td>
      <td>0.000414</td>
      <td>0.000786</td>
      <td>-0.000439</td>
      <td>-0.003476</td>
      <td>0.002329</td>
      <td>-0.061405</td>
      <td>0.036724</td>
    </tr>
    <tr>
      <th>V20</th>
      <td>-0.051160</td>
      <td>-0.002032</td>
      <td>-0.009700</td>
      <td>-0.006893</td>
      <td>0.003787</td>
      <td>-0.016817</td>
      <td>0.011611</td>
      <td>0.021419</td>
      <td>-0.005609</td>
      <td>-0.005520</td>
      <td>-0.006727</td>
      <td>0.000344</td>
      <td>-0.004597</td>
      <td>0.001111</td>
      <td>0.001126</td>
      <td>-0.000107</td>
      <td>0.002739</td>
      <td>-0.000987</td>
      <td>0.001211</td>
      <td>-0.000780</td>
      <td>1.000000</td>
      <td>-0.000435</td>
      <td>0.001689</td>
      <td>0.013348</td>
      <td>0.001558</td>
      <td>0.002580</td>
      <td>0.002351</td>
      <td>0.025160</td>
      <td>-0.023010</td>
      <td>0.378698</td>
      <td>0.021953</td>
    </tr>
    <tr>
      <th>V21</th>
      <td>0.044253</td>
      <td>-0.001978</td>
      <td>-0.003032</td>
      <td>-0.002979</td>
      <td>0.003349</td>
      <td>-0.008510</td>
      <td>0.005147</td>
      <td>0.009986</td>
      <td>-0.000250</td>
      <td>-0.001672</td>
      <td>-0.003130</td>
      <td>0.000816</td>
      <td>-0.000582</td>
      <td>0.000272</td>
      <td>-0.001935</td>
      <td>0.001392</td>
      <td>0.003097</td>
      <td>0.000445</td>
      <td>0.001289</td>
      <td>0.001622</td>
      <td>-0.000435</td>
      <td>1.000000</td>
      <td>0.002411</td>
      <td>0.005986</td>
      <td>-0.000591</td>
      <td>0.003180</td>
      <td>0.001287</td>
      <td>0.012752</td>
      <td>-0.011497</td>
      <td>0.122292</td>
      <td>0.042515</td>
    </tr>
    <tr>
      <th>V22</th>
      <td>0.144670</td>
      <td>0.002074</td>
      <td>0.004273</td>
      <td>0.001248</td>
      <td>-0.002147</td>
      <td>0.002784</td>
      <td>-0.002171</td>
      <td>-0.003077</td>
      <td>-0.001087</td>
      <td>-0.001095</td>
      <td>0.000088</td>
      <td>0.000030</td>
      <td>-0.000502</td>
      <td>0.000276</td>
      <td>0.001396</td>
      <td>-0.000730</td>
      <td>-0.002450</td>
      <td>-0.000404</td>
      <td>-0.001111</td>
      <td>-0.001137</td>
      <td>0.001689</td>
      <td>0.002411</td>
      <td>1.000000</td>
      <td>-0.001151</td>
      <td>-0.001437</td>
      <td>-0.000921</td>
      <td>0.000424</td>
      <td>-0.003481</td>
      <td>0.001312</td>
      <td>-0.070336</td>
      <td>0.000425</td>
    </tr>
    <tr>
      <th>V23</th>
      <td>0.049683</td>
      <td>0.010848</td>
      <td>0.007231</td>
      <td>0.008481</td>
      <td>-0.001533</td>
      <td>0.007772</td>
      <td>-0.003562</td>
      <td>-0.008366</td>
      <td>0.005675</td>
      <td>-0.002803</td>
      <td>-0.000647</td>
      <td>0.002191</td>
      <td>0.000464</td>
      <td>-0.001214</td>
      <td>0.000020</td>
      <td>-0.001792</td>
      <td>-0.005952</td>
      <td>-0.000381</td>
      <td>0.001496</td>
      <td>-0.001297</td>
      <td>0.013348</td>
      <td>0.005986</td>
      <td>-0.001151</td>
      <td>1.000000</td>
      <td>-0.003250</td>
      <td>-0.001691</td>
      <td>-0.000300</td>
      <td>-0.001166</td>
      <td>-0.001869</td>
      <td>-0.117349</td>
      <td>-0.001647</td>
    </tr>
    <tr>
      <th>V24</th>
      <td>-0.015547</td>
      <td>-0.001089</td>
      <td>0.002603</td>
      <td>-0.000150</td>
      <td>-0.001154</td>
      <td>0.000823</td>
      <td>-0.001478</td>
      <td>-0.002986</td>
      <td>0.001012</td>
      <td>0.000655</td>
      <td>0.000737</td>
      <td>-0.000692</td>
      <td>0.000243</td>
      <td>0.000381</td>
      <td>-0.000841</td>
      <td>0.001198</td>
      <td>0.000610</td>
      <td>0.000838</td>
      <td>0.001445</td>
      <td>0.000414</td>
      <td>0.001558</td>
      <td>-0.000591</td>
      <td>-0.001437</td>
      <td>-0.003250</td>
      <td>1.000000</td>
      <td>0.000881</td>
      <td>-0.001981</td>
      <td>-0.002252</td>
      <td>0.003436</td>
      <td>0.001810</td>
      <td>-0.007020</td>
    </tr>
    <tr>
      <th>V25</th>
      <td>-0.231976</td>
      <td>0.003159</td>
      <td>0.003127</td>
      <td>0.003749</td>
      <td>-0.000707</td>
      <td>0.004833</td>
      <td>-0.002102</td>
      <td>-0.003375</td>
      <td>0.002866</td>
      <td>-0.001328</td>
      <td>-0.000054</td>
      <td>-0.001255</td>
      <td>0.000539</td>
      <td>-0.001991</td>
      <td>0.001875</td>
      <td>-0.002857</td>
      <td>-0.000658</td>
      <td>0.000736</td>
      <td>0.000802</td>
      <td>0.000786</td>
      <td>0.002580</td>
      <td>0.003180</td>
      <td>-0.000921</td>
      <td>-0.001691</td>
      <td>0.000881</td>
      <td>1.000000</td>
      <td>0.001031</td>
      <td>-0.004543</td>
      <td>0.001009</td>
      <td>-0.053393</td>
      <td>0.003089</td>
    </tr>
    <tr>
      <th>V26</th>
      <td>-0.040369</td>
      <td>0.002461</td>
      <td>0.002701</td>
      <td>0.001626</td>
      <td>-0.000590</td>
      <td>0.002322</td>
      <td>-0.002203</td>
      <td>-0.004025</td>
      <td>0.001722</td>
      <td>0.000409</td>
      <td>0.001100</td>
      <td>0.000354</td>
      <td>0.001393</td>
      <td>-0.001184</td>
      <td>-0.001374</td>
      <td>-0.001119</td>
      <td>-0.001295</td>
      <td>0.000540</td>
      <td>-0.000488</td>
      <td>-0.000439</td>
      <td>0.002351</td>
      <td>0.001287</td>
      <td>0.000424</td>
      <td>-0.000300</td>
      <td>-0.001981</td>
      <td>0.001031</td>
      <td>1.000000</td>
      <td>-0.002380</td>
      <td>0.001364</td>
      <td>-0.008603</td>
      <td>0.004288</td>
    </tr>
    <tr>
      <th>V27</th>
      <td>-0.005736</td>
      <td>0.014184</td>
      <td>0.013555</td>
      <td>0.013268</td>
      <td>-0.007427</td>
      <td>0.022597</td>
      <td>-0.012878</td>
      <td>-0.025285</td>
      <td>0.006867</td>
      <td>0.000861</td>
      <td>0.003633</td>
      <td>-0.003505</td>
      <td>0.003483</td>
      <td>-0.004479</td>
      <td>0.001623</td>
      <td>-0.003624</td>
      <td>-0.006406</td>
      <td>0.004757</td>
      <td>0.002055</td>
      <td>-0.003476</td>
      <td>0.025160</td>
      <td>0.012752</td>
      <td>-0.003481</td>
      <td>-0.001166</td>
      <td>-0.002252</td>
      <td>-0.004543</td>
      <td>-0.002380</td>
      <td>1.000000</td>
      <td>0.006418</td>
      <td>-0.004428</td>
      <td>0.016901</td>
    </tr>
    <tr>
      <th>V28</th>
      <td>-0.009289</td>
      <td>-0.013830</td>
      <td>-0.015893</td>
      <td>-0.009067</td>
      <td>0.004131</td>
      <td>-0.010706</td>
      <td>0.008897</td>
      <td>0.017643</td>
      <td>-0.009391</td>
      <td>0.003987</td>
      <td>0.001012</td>
      <td>0.003802</td>
      <td>-0.001420</td>
      <td>0.001209</td>
      <td>-0.003638</td>
      <td>0.005619</td>
      <td>0.005165</td>
      <td>-0.002350</td>
      <td>-0.003434</td>
      <td>0.002329</td>
      <td>-0.023010</td>
      <td>-0.011497</td>
      <td>0.001312</td>
      <td>-0.001869</td>
      <td>0.003436</td>
      <td>0.001009</td>
      <td>0.001364</td>
      <td>0.006418</td>
      <td>1.000000</td>
      <td>0.033896</td>
      <td>0.010773</td>
    </tr>
    <tr>
      <th>Amount</th>
      <td>-0.011328</td>
      <td>-0.228808</td>
      <td>-0.537855</td>
      <td>-0.207587</td>
      <td>0.098695</td>
      <td>-0.367801</td>
      <td>0.201285</td>
      <td>0.377417</td>
      <td>-0.097939</td>
      <td>-0.044312</td>
      <td>-0.099188</td>
      <td>-0.001032</td>
      <td>-0.005946</td>
      <td>0.004013</td>
      <td>0.037325</td>
      <td>-0.006642</td>
      <td>-0.008466</td>
      <td>0.010491</td>
      <td>0.035866</td>
      <td>-0.061405</td>
      <td>0.378698</td>
      <td>0.122292</td>
      <td>-0.070336</td>
      <td>-0.117349</td>
      <td>0.001810</td>
      <td>-0.053393</td>
      <td>-0.008603</td>
      <td>-0.004428</td>
      <td>0.033896</td>
      <td>1.000000</td>
      <td>0.006506</td>
    </tr>
    <tr>
      <th>Class</th>
      <td>-0.012800</td>
      <td>-0.103095</td>
      <td>0.093795</td>
      <td>-0.196385</td>
      <td>0.134044</td>
      <td>-0.099712</td>
      <td>-0.042548</td>
      <td>-0.196860</td>
      <td>0.013376</td>
      <td>-0.099674</td>
      <td>-0.222186</td>
      <td>0.156553</td>
      <td>-0.262903</td>
      <td>-0.003179</td>
      <td>-0.304232</td>
      <td>-0.004350</td>
      <td>-0.201828</td>
      <td>-0.333463</td>
      <td>-0.114699</td>
      <td>0.036724</td>
      <td>0.021953</td>
      <td>0.042515</td>
      <td>0.000425</td>
      <td>-0.001647</td>
      <td>-0.007020</td>
      <td>0.003089</td>
      <td>0.004288</td>
      <td>0.016901</td>
      <td>0.010773</td>
      <td>0.006506</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-ed73ce31-6912-4b2c-b018-8e21e7f01d40')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-ed73ce31-6912-4b2c-b018-8e21e7f01d40 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-ed73ce31-6912-4b2c-b018-8e21e7f01d40');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Creating separate dataframes for fraudulent and non-fradulent records</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">data_fraud</span><span class="o">=</span><span class="n">data_train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">data_train</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">]</span>
<span class="n">data_normal</span><span class="o">=</span><span class="n">data_train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">data_train</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total number of fraudulent transactions are&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_fraud</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total number of non fradulent TRANSCATIONS are&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_normal</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Total number of fraudulent transactions are 394
Total number of non fradulent TRANSCATIONS are 227451
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Storing the number of fraudulent and non fraudulent transactions in variable called count_class</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">count_class</span> <span class="o">=</span> <span class="n">data_train</span><span class="o">.</span><span class="n">Class</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
<span class="n">count_class</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0    227451
1       394
Name: Class, dtype: int64</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Visualise the count of normal and fraud transactions</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Transaction class distribution&#39;</span><span class="p">)</span>
<span class="n">LABELS</span> <span class="o">=</span><span class="p">[</span><span class="s1">&#39;Normal&#39;</span><span class="p">,</span><span class="s1">&#39;Fraud&#39;</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Class&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span><span class="n">LABELS</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Frequency&#39;</span><span class="p">)</span>
<span class="n">count_class</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;bar&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7fd341eda8d0&gt;</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Visualizing the Amount per transaction in both fraudulent and non fraudulent transactions</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">data_fraud</span><span class="o">.</span><span class="n">Amount</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>count     394.000000
mean      127.306523
std       264.533907
min         0.000000
25%         1.000000
50%        11.395000
75%       106.385000
max      2125.870000
Name: Amount, dtype: float64</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">data_normal</span><span class="o">.</span><span class="n">Amount</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>count    227451.000000
mean         88.455144
std         248.066088
min           0.000000
25%           5.640000
50%          22.000000
75%          77.000000
max       19656.530000
Name: Amount, dtype: float64</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">fraud1</span><span class="p">,(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">fraud1</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Amount per transaction by class&quot;</span><span class="p">)</span>

<span class="n">bins</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">data_fraud</span><span class="o">.</span><span class="n">Amount</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">data_normal</span><span class="o">.</span><span class="n">Amount</span><span class="p">,</span> <span class="n">bins</span> <span class="o">=</span> <span class="n">bins</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Fraud&quot;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Normal&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Amount $&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Number of transactions&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">3000</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yscale</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>HANDLING IMBALANCED DATASET</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">imblearn</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Requirement already satisfied: imblearn in /usr/local/lib/python3.7/dist-packages (0.0)
Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (from imblearn) (0.8.1)
Requirement already satisfied: scikit-learn&gt;=0.24 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn-&gt;imblearn) (1.0.1)
Requirement already satisfied: numpy&gt;=1.13.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn-&gt;imblearn) (1.19.5)
Requirement already satisfied: scipy&gt;=0.19.1 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn-&gt;imblearn) (1.4.1)
Requirement already satisfied: joblib&gt;=0.11 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn-&gt;imblearn) (1.1.0)
Requirement already satisfied: threadpoolctl&gt;=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn&gt;=0.24-&gt;imbalanced-learn-&gt;imblearn) (3.0.0)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Logistic Regression model on unbalanced data</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span><span class="n">accuracy_score</span><span class="p">,</span><span class="n">classification_report</span><span class="p">,</span><span class="n">f1_score</span><span class="p">,</span><span class="n">roc_auc_score</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">model_log</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">X</span><span class="o">=</span> <span class="n">data_train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;Class&#39;</span><span class="p">,</span><span class="n">axis</span> <span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">data_train</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span>
<span class="n">ytest</span> <span class="o">=</span> <span class="n">data_test_hidden</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">X_train</span><span class="p">,</span><span class="n">X_val</span><span class="p">,</span><span class="n">Y_train</span><span class="p">,</span><span class="n">Y_val</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span><span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span><span class="n">random_state</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span><span class="n">stratify</span> <span class="o">=</span> <span class="n">Y</span><span class="p">)</span>
<span class="n">model_log</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">Y_train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>LogisticRegression()</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1">#prediction on train data (unbalanced)</span>
<span class="n">Y_train_prediction</span> <span class="o">=</span> <span class="n">model_log</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">Y_train</span><span class="p">,</span><span class="n">Y_train_prediction</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>              precision    recall  f1-score   support

           0       1.00      1.00      1.00    181961
           1       0.80      0.69      0.74       315

    accuracy                           1.00    182276
   macro avg       0.90      0.84      0.87    182276
weighted avg       1.00      1.00      1.00    182276

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1"># prediction on test data (fitting done on unbalanced data)</span>
<span class="n">Y_test_prediction</span> <span class="o">=</span> <span class="n">model_log</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span><span class="n">Y_test_prediction</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56864
           1       0.75      0.63      0.69        98

    accuracy                           1.00     56962
   macro avg       0.87      0.82      0.84     56962
weighted avg       1.00      1.00      1.00     56962

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Undersampling the data</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">data_normal_under</span> <span class="o">=</span> <span class="n">data_normal</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">count_class</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">data_normal_under</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(394, 31)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">data_under</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">data_normal_under</span><span class="p">,</span><span class="n">data_fraud</span><span class="p">],</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">data_under</span><span class="o">.</span><span class="n">Class</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>1    394
0    394
Name: Class, dtype: int64</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">data_under</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(788, 31)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">data_under</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;Class&#39;</span><span class="p">,</span><span class="n">axis</span> <span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data_under</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1"># Splitting the undersampled data into train and test set</span>
<span class="n">Xtrain</span><span class="p">,</span><span class="n">Xval</span><span class="p">,</span><span class="n">Ytrain</span><span class="p">,</span><span class="n">Yval</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span><span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span><span class="p">,</span><span class="n">stratify</span> <span class="o">=</span> <span class="n">y</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">Ytrain</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>1    315
0    315
Name: Class, dtype: int64</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Applying Logistic Regression Model to the data after undersampling</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">model1_log</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
<span class="n">model1_log</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">,</span><span class="n">Ytrain</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>LogisticRegression()</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1"># model Evaluation</span>

<span class="c1"># Report for logistic regression (after undersampling) on train data</span>
<span class="n">yunder_log_pred</span> <span class="o">=</span> <span class="n">model1_log</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">)</span>
<span class="c1">#printytest_under_pred)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ROC_AUC-SCORE obtained after logistic regression modeling on the undersampled train data is&quot;</span><span class="p">,</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">Ytrain</span><span class="p">,</span><span class="n">yunder_log_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">Ytrain</span><span class="p">,</span><span class="n">yunder_log_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;F1 SCORE obtained after logistic regression modeling on the undersampled train data is&quot;</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">Ytrain</span><span class="p">,</span><span class="n">yunder_log_pred</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>ROC_AUC-SCORE obtained after logistic regression modeling on the undersampled train data is 0.9555555555555556
              precision    recall  f1-score   support

           0       0.93      0.98      0.96       315
           1       0.98      0.93      0.95       315

    accuracy                           0.96       630
   macro avg       0.96      0.96      0.96       630
weighted avg       0.96      0.96      0.96       630

F1 SCORE obtained after logistic regression modeling on the undersampled train data is 0.9543973941368079
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1"># Report for logistic regression (after undersampling) on test data</span>

<span class="n">ytest_under_pred</span> <span class="o">=</span> <span class="n">model1_log</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span><span class="n">ytest_under_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ROC_AUC-SCORE obtained after logistic regression modeling on the test data is&quot;</span><span class="p">,</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span><span class="n">ytest_under_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;F1 SCORE obtained after logistic regression modeling on the test data is&quot;</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span><span class="n">ytest_under_pred</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>              precision    recall  f1-score   support

           0       1.00      0.96      0.98     56864
           1       0.03      0.88      0.06        98

    accuracy                           0.96     56962
   macro avg       0.52      0.92      0.52     56962
weighted avg       1.00      0.96      0.98     56962

ROC_AUC-SCORE obtained after logistic regression modeling on the test data is 0.9170482310819656
F1 SCORE obtained after logistic regression modeling on the test data is 0.0647834274952919
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Oversampling the data</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">data_fraud_over</span> <span class="o">=</span> <span class="n">data_fraud</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">count_class</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">replace</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">data_over</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">data_fraud_over</span><span class="p">,</span><span class="n">data_normal</span><span class="p">],</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">data_over</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(454902, 31)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">data_over</span><span class="o">.</span><span class="n">Class</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>1    227451
0    227451
Name: Class, dtype: int64</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">x1</span> <span class="o">=</span> <span class="n">data_over</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;Class&quot;</span><span class="p">,</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y1</span> <span class="o">=</span> <span class="n">data_over</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1"># Splitting the oversampled data into train and test set</span>
<span class="n">X1train</span><span class="p">,</span><span class="n">X1val</span><span class="p">,</span><span class="n">Y1train</span><span class="p">,</span><span class="n">Y1val</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span><span class="n">y1</span><span class="p">,</span><span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span><span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span><span class="p">,</span><span class="n">stratify</span> <span class="o">=</span> <span class="n">y1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Logistic regression on oversampled data</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">model1_log</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X1train</span><span class="p">,</span><span class="n">Y1train</span><span class="p">)</span>
<span class="n">X1train_prediction</span> <span class="o">=</span> <span class="n">model1_log</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X1train</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">X1train_prediction</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">Y1train</span><span class="p">,</span><span class="n">X1train_prediction</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;the ROC_AUC score after applying logistic regression model on oversampled training data set is&quot;</span> <span class="p">,</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">Y1train</span><span class="p">,</span> <span class="n">X1train_prediction</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;the F1 score after applying logistic regression model on oversampled  training data set is&quot;</span> <span class="p">,</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">Y1train</span><span class="p">,</span><span class="n">X1train_prediction</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[0 1 1 ... 0 1 0]
              precision    recall  f1-score   support

           0       0.92      0.97      0.94    181960
           1       0.97      0.92      0.94    181961

    accuracy                           0.94    363921
   macro avg       0.94      0.94      0.94    363921
weighted avg       0.94      0.94      0.94    363921

the ROC_AUC score after applying logistic regression model on oversampled training data set is 0.9416000332049683
the F1 score after applying logistic regression model on oversampled  training data set is 0.9400606359726433
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong><em>Logistic regression model evaluation on test data</em></strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">y_test</span> <span class="o">=</span> <span class="n">data_test_hidden</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="p">(</span><span class="n">model1_log</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">data_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.9667673185632527</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1">#Report for logistic regression after  on validation data set</span>
<span class="n">yval_log_pred</span> <span class="o">=</span> <span class="n">model1_log</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X1val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">Y1val</span><span class="p">,</span><span class="n">yval_log_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The ROC_AUC score after applying logistic regression model on validation data set is&quot;</span><span class="p">,</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">Y1val</span><span class="p">,</span><span class="n">yval_log_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The F1 score after applying logistic regression model on validation data set is&quot;</span><span class="p">,</span><span class="n">f1_score</span><span class="p">(</span><span class="n">Y1val</span><span class="p">,</span><span class="n">yval_log_pred</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>              precision    recall  f1-score   support

           0       0.92      0.97      0.94     45491
           1       0.97      0.92      0.94     45490

    accuracy                           0.94     90981
   macro avg       0.94      0.94      0.94     90981
weighted avg       0.94      0.94      0.94     90981

The ROC_AUC score after applying logistic regression model on validation data set is 0.9417567943439676
The F1 score after applying logistic regression model on validation data set is 0.9402572804040723
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1"># Report for logistic regression (after oversampling) on test data</span>

<span class="n">ytest_overlog_pred</span> <span class="o">=</span> <span class="n">model1_log</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span><span class="n">ytest_overlog_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The ROC_AUC score after applying logistic regression model on test data set is&quot;</span><span class="p">,</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span><span class="n">ytest_overlog_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The F1 score after applying logistic regression model on test data set is&quot;</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span><span class="n">ytest_overlog_pred</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>              precision    recall  f1-score   support

           0       1.00      0.97      0.98     56864
           1       0.04      0.87      0.08        98

    accuracy                           0.97     56962
   macro avg       0.52      0.92      0.53     56962
weighted avg       1.00      0.97      0.98     56962

The ROC_AUC score after applying logistic regression model on test data set is 0.9171427997197753
The F1 score after applying logistic regression model on test data set is 0.08240426563257391
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>SVM Modeling on oversampled data</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">model_svm</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">model_svm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X1train</span><span class="p">,</span><span class="n">Y1train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">ypred_svm_over</span> <span class="o">=</span> <span class="n">model_svm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data_test</span><span class="p">)</span>    
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span><span class="n">ypred_svm_over</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The ROC_AUC score after applying svm model on test data set is&quot;</span><span class="p">,</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span><span class="n">ypred_svm_over</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The F1 score after applying svm on test data set is&quot;</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span><span class="n">ypred_svm_over</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>SVM Modelling on undersampled data</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">model_svm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">,</span><span class="n">Ytrain</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">ypred_svm_over</span> <span class="o">=</span> <span class="n">model_svm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span><span class="n">ypred_svm_over</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The ROC_AUC score after applying svm model on test data set is&quot;</span><span class="p">,</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span><span class="n">ypred_svm_over</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The F1 score after applying svm on test data set is&quot;</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span><span class="n">ypred_svm_over</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Naive Bayes Model on undersampled data</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">model_nb</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">model_nb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">,</span><span class="n">Ytrain</span><span class="p">)</span>
<span class="n">ypred_nb_test_under</span> <span class="o">=</span> <span class="n">model_nb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span><span class="n">ypred_nb_test_under</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The ROC_AUC score after applying naive bayes model on test data set is&quot;</span><span class="p">,</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span><span class="n">ypred_nb_test_under</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The F1 score after applying naive bayes on test data set is&quot;</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span><span class="n">ypred_nb_test_under</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Naive Bayes Model on oversampled data</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">model_nb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X1train</span><span class="p">,</span><span class="n">Y1train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">ypred_nb_over</span> <span class="o">=</span> <span class="n">model_nb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data_test</span><span class="p">)</span>    
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span><span class="n">ypred_nb_over</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The ROC_AUC score after applying naive bayes model on test data set is&quot;</span><span class="p">,</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span><span class="n">ypred_nb_over</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The F1 score after applying naive bayes on test data set is&quot;</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span><span class="n">ypred_nb_over</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">imbalanced</span><span class="o">-</span><span class="n">Learn</span>
<span class="kn">import</span> <span class="nn">imblearn</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Oversampling by SMOTE</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">imblearn.over_sampling</span> <span class="kn">import</span> <span class="n">SMOTE</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">smote</span> <span class="o">=</span> <span class="n">SMOTE</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">X_sm</span><span class="p">,</span><span class="n">y_sm</span> <span class="o">=</span> <span class="n">smote</span><span class="o">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">Y_train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">X_sm</span><span class="p">,</span><span class="n">y_sm</span> <span class="o">=</span> <span class="n">smote</span><span class="o">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">y_sm</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">XS_train</span><span class="p">,</span><span class="n">XS_val</span><span class="p">,</span><span class="n">YS_train</span><span class="p">,</span><span class="n">YS_val</span> <span class="o">=</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">X_sm</span><span class="p">,</span><span class="n">y_sm</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span><span class="n">stratify</span><span class="o">=</span><span class="n">y_sm</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">YS_train</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">YS_val</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">

<pre><code># This is formatted as code</code></pre>
<p><strong>Logistic regression model on test data after oversampling by SMOTE</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">model_log</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">XS_train</span><span class="p">,</span><span class="n">YS_train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">ytestsm_prediction</span> <span class="o">=</span> <span class="n">model_log</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span><span class="n">ytestsm_prediction</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The ROC_AUC score after applying logistic regression model on test data set is&quot;</span><span class="p">,</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span><span class="n">ytestsm_prediction</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The F1 score after applying logistic regression on test data set is&quot;</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span><span class="n">ytestsm_prediction</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">ytestsm_svm_pred</span> <span class="o">=</span> <span class="n">model_svm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span><span class="n">ytestsm_svm_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The ROC_AUC score after applying svm model on test data set is&quot;</span><span class="p">,</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span><span class="n">ytestsm_svm_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The F1 score after applying svm on test data set is&quot;</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span><span class="n">ytestsm_svm_pred</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">model_nb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">XS_train</span><span class="p">,</span><span class="n">YS_train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">ytestsm_nb_pred</span> <span class="o">=</span> <span class="n">model_nb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span><span class="n">ytestsm_nb_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The ROC_AUC score after applying naive bayes model on test data after SMOTE oversampling is&quot;</span><span class="p">,</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span><span class="n">ytestsm_nb_pred</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The F1 score after applying naive bayes model on test data after SMOTE oversampling is&quot;</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span><span class="n">ytestsm_nb_pred</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Applying-random-forest-classifier"><strong>Applying random forest classifier</strong><a class="anchor-link" href="#Applying-random-forest-classifier">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">RandomizedSearchCV</span>
<span class="n">rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">()</span>
<span class="n">rf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">Y_train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1"># Number of trees in random forest</span>
<span class="n">n_estimators</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">start</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="mi">80</span><span class="p">,</span> <span class="n">num</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)]</span>
<span class="c1"># Number of features to consider at every split</span>
<span class="n">max_features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="s1">&#39;sqrt&#39;</span><span class="p">]</span>
<span class="c1"># Maximum number of levels in tree</span>
<span class="n">max_depth</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">]</span>
<span class="c1"># Minimum number of samples required to split a node</span>
<span class="n">min_samples_split</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="c1"># Minimum number of samples required at each leaf node</span>
<span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="c1"># Method of selecting samples for training each tree</span>
<span class="n">bootstrap</span> <span class="o">=</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">NameError</span>                                 Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-1-9d6d5878f0a6&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> <span class="ansi-red-fg"># Number of trees in random forest</span>
<span class="ansi-green-fg">----&gt; 2</span><span class="ansi-red-fg"> </span>n_estimators <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">[</span>int<span class="ansi-blue-fg">(</span>x<span class="ansi-blue-fg">)</span> <span class="ansi-green-fg">for</span> x <span class="ansi-green-fg">in</span> np<span class="ansi-blue-fg">.</span>linspace<span class="ansi-blue-fg">(</span>start <span class="ansi-blue-fg">=</span> <span class="ansi-cyan-fg">10</span><span class="ansi-blue-fg">,</span> stop <span class="ansi-blue-fg">=</span> <span class="ansi-cyan-fg">80</span><span class="ansi-blue-fg">,</span> num <span class="ansi-blue-fg">=</span> <span class="ansi-cyan-fg">10</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">]</span>
<span class="ansi-green-intense-fg ansi-bold">      3</span> <span class="ansi-red-fg"># Number of features to consider at every split</span>
<span class="ansi-green-intense-fg ansi-bold">      4</span> max_features <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">&#39;auto&#39;</span><span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">&#39;sqrt&#39;</span><span class="ansi-blue-fg">]</span>
<span class="ansi-green-intense-fg ansi-bold">      5</span> <span class="ansi-red-fg"># Maximum number of levels in tree</span>

<span class="ansi-red-fg">NameError</span>: name &#39;np&#39; is not defined</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1">#creating paramater grid</span>

<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="n">n_estimators</span><span class="p">,</span>
               <span class="s1">&#39;max_features&#39;</span><span class="p">:</span> <span class="n">max_features</span><span class="p">,</span>
               <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="n">max_depth</span><span class="p">,</span>
               <span class="s1">&#39;min_samples_split&#39;</span><span class="p">:</span> <span class="n">min_samples_split</span><span class="p">,</span>
               <span class="s1">&#39;min_samples_leaf&#39;</span><span class="p">:</span> <span class="n">min_samples_leaf</span><span class="p">,</span>
               <span class="s1">&#39;bootstrap&#39;</span><span class="p">:</span> <span class="n">bootstrap</span><span class="p">}</span>
<span class="nb">print</span><span class="p">(</span><span class="n">param_grid</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>{&#39;n_estimators&#39;: [10, 17, 25, 33, 41, 48, 56, 64, 72, 80], &#39;max_features&#39;: [&#39;auto&#39;, &#39;sqrt&#39;], &#39;max_depth&#39;: [2, 4], &#39;min_samples_split&#39;: [2, 5], &#39;min_samples_leaf&#39;: [1, 2], &#39;bootstrap&#39;: [True, False]}
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">y_predrf_unbalanced</span> <span class="o">=</span> <span class="n">rf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>


<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">Y_train</span><span class="p">,</span><span class="n">y_predrf_unbalanced</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>              precision    recall  f1-score   support

           0       1.00      1.00      1.00    181961
           1       1.00      1.00      1.00       315

    accuracy                           1.00    182276
   macro avg       1.00      1.00      1.00    182276
weighted avg       1.00      1.00      1.00    182276

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Using-Randomised-Search"><strong><em>Using Randomised Search</em></strong><a class="anchor-link" href="#Using-Randomised-Search">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">rf_random</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span><span class="n">estimator</span> <span class="o">=</span> <span class="n">rf</span><span class="p">,</span> <span class="n">param_distributions</span> <span class="o">=</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">n_iter</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">n_jobs</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># Fit the random search model</span>
<span class="n">rf_random</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Fitting 3 folds for each of 100 candidates, totalling 300 fits
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_iter=100,
                   n_jobs=-1,
                   param_distributions={&#39;bootstrap&#39;: [True, False],
                                        &#39;max_depth&#39;: [2, 4],
                                        &#39;max_features&#39;: [&#39;auto&#39;, &#39;sqrt&#39;],
                                        &#39;min_samples_leaf&#39;: [1, 2],
                                        &#39;min_samples_split&#39;: [2, 5],
                                        &#39;n_estimators&#39;: [10, 17, 25, 33, 41, 48,
                                                         56, 64, 72, 80]},
                   random_state=42, verbose=2)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong><em>Printing best parameters</em></strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">rf_random</span><span class="o">.</span><span class="n">best_params_</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>{&#39;bootstrap&#39;: False,
 &#39;max_depth&#39;: 4,
 &#39;max_features&#39;: &#39;auto&#39;,
 &#39;min_samples_leaf&#39;: 2,
 &#39;min_samples_split&#39;: 2,
 &#39;n_estimators&#39;: 25}</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong><em>predicitng on Train set</em></strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">y_predrf</span><span class="o">=</span> <span class="n">rf_random</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">Y_train</span><span class="p">,</span><span class="n">y_predrf</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>              precision    recall  f1-score   support

           0       1.00      1.00      1.00    181961
           1       0.94      0.77      0.85       315

    accuracy                           1.00    182276
   macro avg       0.97      0.89      0.92    182276
weighted avg       1.00      1.00      1.00    182276

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong><em>predicting on validation set</em></strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">y_predrf</span><span class="o">=</span> <span class="n">rf_random</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_val</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">Y_val</span><span class="p">,</span><span class="n">y_predrf</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>              precision    recall  f1-score   support

           0       1.00      1.00      1.00     45490
           1       0.87      0.67      0.76        79

    accuracy                           1.00     45569
   macro avg       0.93      0.84      0.88     45569
weighted avg       1.00      1.00      1.00     45569

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">ytest_rf</span> <span class="o">=</span> <span class="n">data_test_hidden</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ytest_rf</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>0        0
1        0
2        0
3        0
4        0
        ..
56957    0
56958    0
56959    0
56960    0
56961    0
Name: Class, Length: 56962, dtype: int64
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong><em>predicting on test dataset</em></strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">y_predrf</span><span class="o">=</span> <span class="n">rf_random</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">ytest_rf</span><span class="p">,</span><span class="n">y_predrf</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The ROC_AUC score after applying random forest(with hyperparameter tuning) on test data set is&quot;</span><span class="p">,</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span><span class="n">y_predrf</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The F1 score after applying random forest(with hyperparameter tuning) on test data set is&quot;</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span><span class="n">y_predrf</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56864
           1       0.90      0.61      0.73        98

    accuracy                           1.00     56962
   macro avg       0.95      0.81      0.86     56962
weighted avg       1.00      1.00      1.00     56962

The ROC_AUC score after applying random forest(with hyperparameter tuning) on test data set is 0.8060608986138068
The F1 score after applying random forest(with hyperparameter tuning) on test data set is 0.7272727272727273
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>XGBOOST</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">xgboost</span> <span class="k">as</span> <span class="nn">xgb</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span>
<span class="n">dmatrix</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">DMatrix</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
<span class="n">params</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;objective&#39;</span><span class="p">:</span><span class="s1">&#39;reg:squarederror&#39;</span><span class="p">}</span>
<span class="n">cv_results</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">cv</span><span class="p">(</span><span class="n">dtrain</span><span class="o">=</span><span class="n">dmatrix</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">,</span> <span class="n">nfold</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;rmse&#39;</span><span class="p">},</span> <span class="n">as_pandas</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;RMSE: </span><span class="si">%.2f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">cv_results</span><span class="p">[</span><span class="s1">&#39;test-rmse-mean&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>RMSE: 0.03
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1">#XGboost with hyperparameter tuning (fitted)</span>
<span class="n">params</span><span class="o">=</span><span class="p">{</span> <span class="s1">&#39;objective&#39;</span><span class="p">:</span><span class="s1">&#39;reg:squarederror&#39;</span><span class="p">,</span>
         <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> 
         <span class="s1">&#39;colsample_bylevel&#39;</span><span class="p">:</span><span class="mf">0.5</span><span class="p">,</span>
         <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span><span class="mf">0.01</span><span class="p">,</span>
         <span class="s1">&#39;random_state&#39;</span><span class="p">:</span><span class="mi">20</span><span class="p">}</span>
<span class="n">cv_results</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">cv</span><span class="p">(</span><span class="n">dtrain</span><span class="o">=</span><span class="n">dmatrix</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">,</span> <span class="n">nfold</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;rmse&#39;</span><span class="p">},</span> <span class="n">as_pandas</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">num_boost_round</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;RMSE: </span><span class="si">%.2f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">cv_results</span><span class="p">[</span><span class="s1">&#39;test-rmse-mean&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>RMSE: 0.02
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBClassifier</span>
<span class="n">xb</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">()</span>
<span class="n">xb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">Y_train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>XGBClassifier()</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong><em>predicting using XGBoost model on the train data</em></strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">trainpredict</span> <span class="o">=</span> <span class="n">xb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">trainpredict</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>              precision    recall  f1-score   support

           0       1.00      1.00      1.00    182001
           1       0.86      0.98      0.92       275

    accuracy                           1.00    182276
   macro avg       0.93      0.99      0.96    182276
weighted avg       1.00      1.00      1.00    182276

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong><em>predicting using XGBoost model on the test data</em></strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">testpredict</span> <span class="o">=</span> <span class="n">xb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">ytest_rf</span><span class="p">,</span><span class="n">testpredict</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The ROC_AUC score after applying XGBoost Classifier is&quot;</span><span class="p">,</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">ytest_rf</span><span class="p">,</span><span class="n">testpredict</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The F1 score after applying XGBoost Classifier is&quot;</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">ytest_rf</span><span class="p">,</span><span class="n">testpredict</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56864
           1       0.92      0.71      0.80        98

    accuracy                           1.00     56962
   macro avg       0.96      0.86      0.90     56962
weighted avg       1.00      1.00      1.00     56962

The ROC_AUC score after applying XGBoost Classifier is 0.8570900996864701
The F1 score after applying XGBoost Classifier is 0.8045977011494253
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Building an ANN</strong>
<strong>(a) with only two layers</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Activation</span><span class="p">,</span><span class="n">Dense</span><span class="p">,</span><span class="n">BatchNormalization</span><span class="p">,</span><span class="n">Dropout</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="c1">#from tensorflow.keras.optimizers import optimis</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span> <span class="p">,</span> <span class="n">classification_report</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="kn">import</span> <span class="nn">keras</span>
<span class="kn">from</span> <span class="nn">keras.wrappers.scikit_learn</span> <span class="kn">import</span> <span class="n">KerasClassifier</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">ann_model_2layers</span><span class="p">(</span><span class="n">xtrain</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,</span><span class="n">xtest</span><span class="p">,</span><span class="n">ytest</span><span class="p">,</span><span class="n">neurons</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">epochs</span><span class="p">):</span>
    <span class="c1"># define model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
    <span class="c1"># define first hidden layer and visible layer</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">neurons</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_uniform&#39;</span><span class="p">))</span>
    <span class="c1"># define output layer</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>
    <span class="c1"># define loss and optimizer</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xtrain</span><span class="p">,</span><span class="n">ytrain</span><span class="p">,</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">b</span><span class="p">,</span><span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">)</span>
    <span class="n">y_pred</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xtest</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
    <span class="n">score1</span> <span class="o">=</span>  <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The ROC_AUC Score with&quot;</span><span class="p">,</span><span class="n">neurons</span><span class="p">,</span><span class="s2">&quot;neurons in the first layer and batch size as &quot;</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="s2">&quot;over&quot;</span><span class="p">,</span><span class="n">epochs</span><span class="p">,</span><span class="s2">&quot;epochs is &quot;</span><span class="p">,</span> <span class="n">score1</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span><span class="n">y_pred</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span><span class="n">y_pred</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Running the ANN model (2 Layers ) with 30 EPOCHS</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">ann_model_2layers</span><span class="p">(</span><span class="n">X1train</span><span class="p">,</span><span class="n">Y1train</span><span class="p">,</span><span class="n">data_test</span><span class="p">,</span><span class="n">ytest</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="n">batch_size</span><span class="p">,</span><span class="mi">30</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/30
18197/18197 [==============================] - 22s 1ms/step - loss: 19.1641
Epoch 2/30
18197/18197 [==============================] - 22s 1ms/step - loss: 5.4223
Epoch 3/30
18197/18197 [==============================] - 22s 1ms/step - loss: 5.2403
Epoch 4/30
18197/18197 [==============================] - 22s 1ms/step - loss: 5.3375
Epoch 5/30
18197/18197 [==============================] - 22s 1ms/step - loss: 4.8101
Epoch 6/30
18197/18197 [==============================] - 22s 1ms/step - loss: 4.6533
Epoch 7/30
18197/18197 [==============================] - 22s 1ms/step - loss: 4.3797
Epoch 8/30
18197/18197 [==============================] - 22s 1ms/step - loss: 4.0506
Epoch 9/30
18197/18197 [==============================] - 22s 1ms/step - loss: 3.7830
Epoch 10/30
18197/18197 [==============================] - 22s 1ms/step - loss: 3.4621
Epoch 11/30
18197/18197 [==============================] - 22s 1ms/step - loss: 3.2607
Epoch 12/30
18197/18197 [==============================] - 22s 1ms/step - loss: 3.0364
Epoch 13/30
18197/18197 [==============================] - 22s 1ms/step - loss: 2.6692
Epoch 14/30
18197/18197 [==============================] - 22s 1ms/step - loss: 2.4550
Epoch 15/30
18197/18197 [==============================] - 22s 1ms/step - loss: 1.9421
Epoch 16/30
18197/18197 [==============================] - 22s 1ms/step - loss: 1.3237
Epoch 17/30
18197/18197 [==============================] - 22s 1ms/step - loss: 0.9313
Epoch 18/30
18197/18197 [==============================] - 22s 1ms/step - loss: 0.7156
Epoch 19/30
18197/18197 [==============================] - 22s 1ms/step - loss: 0.3575
Epoch 20/30
18197/18197 [==============================] - 23s 1ms/step - loss: 0.1691
Epoch 21/30
18197/18197 [==============================] - 23s 1ms/step - loss: 0.1610
Epoch 22/30
18197/18197 [==============================] - 22s 1ms/step - loss: 0.1591
Epoch 23/30
18197/18197 [==============================] - 22s 1ms/step - loss: 0.1565
Epoch 24/30
18197/18197 [==============================] - 22s 1ms/step - loss: 0.1535
Epoch 25/30
18197/18197 [==============================] - 22s 1ms/step - loss: 0.1529
Epoch 26/30
18197/18197 [==============================] - 22s 1ms/step - loss: 0.1505
Epoch 27/30
18197/18197 [==============================] - 22s 1ms/step - loss: 0.1509
Epoch 28/30
18197/18197 [==============================] - 22s 1ms/step - loss: 0.1499
Epoch 29/30
18197/18197 [==============================] - 22s 1ms/step - loss: 0.1484
Epoch 30/30
18197/18197 [==============================] - 21s 1ms/step - loss: 0.1524
The ROC_AUC Score with 30 neurons in the first layer and batch size as  20 over 30 epochs is  0.9283756517519782
              precision    recall  f1-score   support

           0       1.00      0.97      0.98     56864
           1       0.05      0.89      0.09        98

    accuracy                           0.97     56962
   macro avg       0.52      0.93      0.54     56962
weighted avg       1.00      0.97      0.98     56962

[[55101  1763]
 [   11    87]]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Building an ANN (b) with two layers with a dropout layer</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">ann_model_2layersDropout</span><span class="p">(</span><span class="n">xtrain</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,</span><span class="n">xtest</span><span class="p">,</span><span class="n">ytest</span><span class="p">,</span><span class="n">neurons1</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">epochs</span><span class="p">):</span>
    <span class="c1"># define model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
    <span class="c1"># define first hidden layer </span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">neurons1</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_uniform&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">))</span>
    <span class="c1"># define output layer</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>
    <span class="c1"># define loss and optimizer</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xtrain</span><span class="p">,</span><span class="n">ytrain</span><span class="p">,</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">b</span><span class="p">,</span><span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">)</span>
    <span class="n">y_pred</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xtest</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
    <span class="n">score1</span> <span class="o">=</span>  <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The ROC_AUC Score with&quot;</span><span class="p">,</span><span class="n">neurons1</span><span class="p">,</span><span class="s2">&quot;neurons in the first layer and batch size as &quot;</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="s2">&quot;over&quot;</span><span class="p">,</span><span class="n">epochs</span><span class="p">,</span><span class="s2">&quot;epochs is &quot;</span><span class="p">,</span> <span class="n">score1</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span><span class="n">y_pred</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span><span class="n">y_pred</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">ann_model_2layersDropout</span><span class="p">(</span><span class="n">X1train</span><span class="p">,</span><span class="n">Y1train</span><span class="p">,</span><span class="n">data_test</span><span class="p">,</span><span class="n">ytest</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="n">batch_size</span><span class="p">,</span><span class="mi">30</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/30
18197/18197 [==============================] - 23s 1ms/step - loss: 112.1264
Epoch 2/30
18197/18197 [==============================] - 22s 1ms/step - loss: 0.6514
Epoch 3/30
18197/18197 [==============================] - 22s 1ms/step - loss: 0.4949
Epoch 4/30
18197/18197 [==============================] - 22s 1ms/step - loss: 0.4192
Epoch 5/30
18197/18197 [==============================] - 22s 1ms/step - loss: 0.4170
Epoch 6/30
18197/18197 [==============================] - 22s 1ms/step - loss: 0.3285
Epoch 7/30
18197/18197 [==============================] - 22s 1ms/step - loss: 0.3055
Epoch 8/30
18197/18197 [==============================] - 22s 1ms/step - loss: 0.2994
Epoch 9/30
18197/18197 [==============================] - 23s 1ms/step - loss: 0.2920
Epoch 10/30
18197/18197 [==============================] - 22s 1ms/step - loss: 0.2904
Epoch 11/30
18197/18197 [==============================] - 22s 1ms/step - loss: 0.2897
Epoch 12/30
18197/18197 [==============================] - 22s 1ms/step - loss: 0.2895
Epoch 13/30
18197/18197 [==============================] - 22s 1ms/step - loss: 0.2916
Epoch 14/30
18197/18197 [==============================] - 22s 1ms/step - loss: 0.2917
Epoch 15/30
18197/18197 [==============================] - 22s 1ms/step - loss: 0.2944
Epoch 16/30
18197/18197 [==============================] - 22s 1ms/step - loss: 0.2832
Epoch 17/30
18197/18197 [==============================] - 22s 1ms/step - loss: 0.2815
Epoch 18/30
18197/18197 [==============================] - 22s 1ms/step - loss: 0.2836
Epoch 19/30
18197/18197 [==============================] - 22s 1ms/step - loss: 0.2791
Epoch 20/30
18197/18197 [==============================] - 22s 1ms/step - loss: 0.2807
Epoch 21/30
18197/18197 [==============================] - 22s 1ms/step - loss: 0.2775
Epoch 22/30
18197/18197 [==============================] - 23s 1ms/step - loss: 0.2875
Epoch 23/30
18197/18197 [==============================] - 24s 1ms/step - loss: 0.2781
Epoch 24/30
18197/18197 [==============================] - 22s 1ms/step - loss: 0.2789
Epoch 25/30
18197/18197 [==============================] - 23s 1ms/step - loss: 0.2786
Epoch 26/30
18197/18197 [==============================] - 22s 1ms/step - loss: 0.2823
Epoch 27/30
18197/18197 [==============================] - 23s 1ms/step - loss: 0.2830
Epoch 28/30
18197/18197 [==============================] - 24s 1ms/step - loss: 0.2818
Epoch 29/30
18197/18197 [==============================] - 24s 1ms/step - loss: 0.2749
Epoch 30/30
18197/18197 [==============================] - 25s 1ms/step - loss: 0.2801
The ROC_AUC Score with 30 neurons in the first layer and batch size as  20 over 30 epochs is  0.9288725408565227
              precision    recall  f1-score   support

           0       1.00      0.99      1.00     56864
           1       0.13      0.87      0.23        98

    accuracy                           0.99     56962
   macro avg       0.57      0.93      0.61     56962
weighted avg       1.00      0.99      0.99     56962

[[56318   546]
 [   13    85]]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">define_model</span><span class="p">(</span><span class="n">activation</span> <span class="o">=</span> <span class="s1">&#39;relu&#39;</span><span class="p">,</span><span class="n">init_weights</span> <span class="o">=</span> <span class="s1">&#39;uniform&#39;</span><span class="p">,</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">):</span>
    <span class="c1"># define model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
    <span class="c1"># define first hidden layer and visible layer</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">init_weights</span><span class="p">))</span>
    <span class="c1">#adding dropout layer</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.1</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">init_weights</span><span class="p">))</span>
    <span class="c1"># define output layer</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">kernel_initializer</span><span class="o">=</span><span class="n">init_weights</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>
    <span class="c1"># define loss and optimizer</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>
                  <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
                  <span class="n">metrics</span> <span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">model</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">KerasClassifier</span><span class="p">(</span><span class="n">build_fn</span><span class="o">=</span><span class="n">define_model</span><span class="p">,</span>
                        <span class="n">epochs</span> <span class="o">=</span> <span class="n">epochs</span><span class="p">,</span>
                        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                        <span class="n">verbose</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">activation</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">]</span>
<span class="n">init_weights</span> <span class="o">=</span><span class="p">[</span><span class="s1">&#39;uniform&#39;</span><span class="p">]</span>
<span class="n">optimizers</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span><span class="s1">&#39;SGD&#39;</span><span class="p">,</span><span class="s1">&#39;RMSprop&#39;</span><span class="p">]</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activation</span><span class="p">,</span><span class="n">init_weights</span><span class="o">=</span><span class="n">init_weights</span><span class="p">,</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizers</span><span class="p">)</span>
<span class="n">grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">param_grid</span> <span class="o">=</span> <span class="n">param_grid</span><span class="p">)</span>
<span class="n">grid_result</span> <span class="o">=</span> <span class="n">grid</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X1train</span><span class="p">,</span><span class="n">Y1train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best: </span><span class="si">% u</span><span class="s2">sing </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">grid_result</span><span class="o">.</span><span class="n">best_score_</span><span class="p">,</span><span class="n">grid_result</span><span class="o">.</span><span class="n">best_params_</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/2
14557/14557 [==============================] - 20s 1ms/step - loss: 0.6442 - accuracy: 0.5992
Epoch 2/2
14557/14557 [==============================] - 19s 1ms/step - loss: 0.5036 - accuracy: 0.7094
3640/3640 [==============================] - 3s 787us/step - loss: 0.2173 - accuracy: 0.9336
Epoch 1/2
14557/14557 [==============================] - 20s 1ms/step - loss: 0.6709 - accuracy: 0.5508
Epoch 2/2
14557/14557 [==============================] - 19s 1ms/step - loss: 0.6512 - accuracy: 0.5605
3640/3640 [==============================] - 3s 789us/step - loss: 0.6436 - accuracy: 0.5688
Epoch 1/2
14557/14557 [==============================] - 20s 1ms/step - loss: 0.6928 - accuracy: 0.5421
Epoch 2/2
14557/14557 [==============================] - 19s 1ms/step - loss: 0.6616 - accuracy: 0.5452
3640/3640 [==============================] - 3s 811us/step - loss: 0.6450 - accuracy: 0.5645
Epoch 1/2
14557/14557 [==============================] - 20s 1ms/step - loss: 0.6738 - accuracy: 0.5456
Epoch 2/2
14557/14557 [==============================] - 19s 1ms/step - loss: 0.6513 - accuracy: 0.5601
3640/3640 [==============================] - 3s 809us/step - loss: 0.6220 - accuracy: 0.5993
Epoch 1/2
14557/14557 [==============================] - 20s 1ms/step - loss: 0.7015 - accuracy: 0.5020
Epoch 2/2
14557/14557 [==============================] - 19s 1ms/step - loss: 0.6931 - accuracy: 0.5010
3640/3640 [==============================] - 3s 816us/step - loss: 0.6922 - accuracy: 0.5001
Epoch 1/2
14557/14557 [==============================] - 16s 1ms/step - loss: 40802952.0000 - accuracy: 0.5001
Epoch 2/2
14557/14557 [==============================] - 17s 1ms/step - loss: 0.6931 - accuracy: 0.4989
3640/3640 [==============================] - 3s 832us/step - loss: 0.6931 - accuracy: 0.5013
Epoch 1/2
14557/14557 [==============================] - 16s 1ms/step - loss: 310.4388 - accuracy: 0.4996
Epoch 2/2
14557/14557 [==============================] - 16s 1ms/step - loss: 0.6931 - accuracy: 0.5012
3640/3640 [==============================] - 3s 871us/step - loss: 0.6931 - accuracy: 0.5005
Epoch 1/2
14557/14557 [==============================] - 18s 1ms/step - loss: 10.9419 - accuracy: 0.5011
Epoch 2/2
14557/14557 [==============================] - 17s 1ms/step - loss: 0.6932 - accuracy: 0.5001
3640/3640 [==============================] - 3s 850us/step - loss: 0.6932 - accuracy: 0.4981
Epoch 1/2
14557/14557 [==============================] - 17s 1ms/step - loss: 10.1484 - accuracy: 0.5019
Epoch 2/2
14557/14557 [==============================] - 17s 1ms/step - loss: 0.6932 - accuracy: 0.5006
3640/3640 [==============================] - 4s 939us/step - loss: 0.6931 - accuracy: 0.4999
Epoch 1/2
14557/14557 [==============================] - 18s 1ms/step - loss: 107575776.0000 - accuracy: 0.4998
Epoch 2/2
14557/14557 [==============================] - 17s 1ms/step - loss: 0.6932 - accuracy: 0.5004
3640/3640 [==============================] - 3s 870us/step - loss: 0.6932 - accuracy: 0.5000
Epoch 1/2
14557/14557 [==============================] - 18s 1ms/step - loss: 0.4485 - accuracy: 0.8024
Epoch 2/2
14557/14557 [==============================] - 18s 1ms/step - loss: 0.2662 - accuracy: 0.8998
3640/3640 [==============================] - 3s 853us/step - loss: 0.3361 - accuracy: 0.9228
Epoch 1/2
14557/14557 [==============================] - 18s 1ms/step - loss: 0.4315 - accuracy: 0.8070
Epoch 2/2
14557/14557 [==============================] - 17s 1ms/step - loss: 0.2689 - accuracy: 0.8994
3640/3640 [==============================] - 3s 870us/step - loss: 0.1989 - accuracy: 0.9296
Epoch 1/2
14557/14557 [==============================] - 20s 1ms/step - loss: 0.4746 - accuracy: 0.8014
Epoch 2/2
14557/14557 [==============================] - 21s 1ms/step - loss: 0.2754 - accuracy: 0.8981
3640/3640 [==============================] - 4s 1ms/step - loss: 0.1961 - accuracy: 0.9298
Epoch 1/2
14557/14557 [==============================] - 20s 1ms/step - loss: 0.4544 - accuracy: 0.7994
Epoch 2/2
14557/14557 [==============================] - 20s 1ms/step - loss: 0.2894 - accuracy: 0.8932
3640/3640 [==============================] - 4s 1ms/step - loss: 0.1916 - accuracy: 0.9316
Epoch 1/2
14557/14557 [==============================] - 20s 1ms/step - loss: 0.4635 - accuracy: 0.7934
Epoch 2/2
14557/14557 [==============================] - 20s 1ms/step - loss: 0.2850 - accuracy: 0.8939
3640/3640 [==============================] - 4s 1ms/step - loss: 0.3315 - accuracy: 0.8244
Epoch 1/2
14557/14557 [==============================] - 24s 2ms/step - loss: 0.6933 - accuracy: 0.5002
Epoch 2/2
14557/14557 [==============================] - 25s 2ms/step - loss: 0.6932 - accuracy: 0.4993
3640/3640 [==============================] - 4s 1ms/step - loss: 0.6931 - accuracy: 0.5013
Epoch 1/2
14557/14557 [==============================] - 25s 2ms/step - loss: 0.6933 - accuracy: 0.5003
Epoch 2/2
14557/14557 [==============================] - 23s 2ms/step - loss: 0.6932 - accuracy: 0.4998
3640/3640 [==============================] - 4s 955us/step - loss: 0.6932 - accuracy: 0.4995
Epoch 1/2
14557/14557 [==============================] - 25s 2ms/step - loss: 0.6933 - accuracy: 0.4984
Epoch 2/2
14557/14557 [==============================] - 25s 2ms/step - loss: 0.6932 - accuracy: 0.4996
3640/3640 [==============================] - 4s 1ms/step - loss: 0.6932 - accuracy: 0.4981
Epoch 1/2
14557/14557 [==============================] - 24s 2ms/step - loss: 0.6932 - accuracy: 0.5030
Epoch 2/2
14557/14557 [==============================] - 26s 2ms/step - loss: 0.6932 - accuracy: 0.5001
3640/3640 [==============================] - 4s 1ms/step - loss: 0.6932 - accuracy: 0.5001
Epoch 1/2
14557/14557 [==============================] - 25s 2ms/step - loss: 0.6933 - accuracy: 0.5005
Epoch 2/2
14557/14557 [==============================] - 23s 2ms/step - loss: 0.6931 - accuracy: 0.4997
3640/3640 [==============================] - 4s 963us/step - loss: 0.6932 - accuracy: 0.5000
Epoch 1/2
14557/14557 [==============================] - 20s 1ms/step - loss: 0.6934 - accuracy: 0.5003
Epoch 2/2
14557/14557 [==============================] - 19s 1ms/step - loss: 0.6934 - accuracy: 0.5003
3640/3640 [==============================] - 4s 967us/step - loss: 0.6931 - accuracy: 0.4989
Epoch 1/2
14557/14557 [==============================] - 19s 1ms/step - loss: 0.6934 - accuracy: 0.5018
Epoch 2/2
14557/14557 [==============================] - 18s 1ms/step - loss: 0.6934 - accuracy: 0.5002
3640/3640 [==============================] - 3s 922us/step - loss: 0.6940 - accuracy: 0.4995
Epoch 1/2
14557/14557 [==============================] - 18s 1ms/step - loss: 0.6935 - accuracy: 0.4980
Epoch 2/2
14557/14557 [==============================] - 18s 1ms/step - loss: 0.6934 - accuracy: 0.5005
3640/3640 [==============================] - 4s 1ms/step - loss: 0.6932 - accuracy: 0.5019
Epoch 1/2
14557/14557 [==============================] - 19s 1ms/step - loss: 0.6934 - accuracy: 0.5022
Epoch 2/2
14557/14557 [==============================] - 19s 1ms/step - loss: 0.6934 - accuracy: 0.5006
3640/3640 [==============================] - 4s 1ms/step - loss: 0.6932 - accuracy: 0.4999
Epoch 1/2
14557/14557 [==============================] - 22s 1ms/step - loss: 0.6934 - accuracy: 0.5026
Epoch 2/2
14557/14557 [==============================] - 20s 1ms/step - loss: 0.6934 - accuracy: 0.5007
3640/3640 [==============================] - 4s 1ms/step - loss: 0.6934 - accuracy: 0.5000
Epoch 1/2
14557/14557 [==============================] - 21s 1ms/step - loss: 0.6933 - accuracy: 0.5007
Epoch 2/2
14557/14557 [==============================] - 21s 1ms/step - loss: 0.6929 - accuracy: 0.4985
3640/3640 [==============================] - 4s 1ms/step - loss: 0.6931 - accuracy: 0.4987
Epoch 1/2
14557/14557 [==============================] - 20s 1ms/step - loss: 0.6932 - accuracy: 0.5025
Epoch 2/2
14557/14557 [==============================] - 21s 1ms/step - loss: 0.6930 - accuracy: 0.4983
3640/3640 [==============================] - 4s 1ms/step - loss: 0.6929 - accuracy: 0.5017
Epoch 1/2
14557/14557 [==============================] - 22s 1ms/step - loss: 0.6933 - accuracy: 0.4999
Epoch 2/2
14557/14557 [==============================] - 20s 1ms/step - loss: 0.6928 - accuracy: 0.5018
3640/3640 [==============================] - 4s 1ms/step - loss: 0.6935 - accuracy: 0.4990
Epoch 1/2
14557/14557 [==============================] - 21s 1ms/step - loss: 0.6933 - accuracy: 0.5005
Epoch 2/2
14557/14557 [==============================] - 21s 1ms/step - loss: 0.6929 - accuracy: 0.5012
3640/3640 [==============================] - 4s 1ms/step - loss: 0.6927 - accuracy: 0.4999
Epoch 1/2
14557/14557 [==============================] - 21s 1ms/step - loss: 0.6933 - accuracy: 0.4998
Epoch 2/2
14557/14557 [==============================] - 20s 1ms/step - loss: 0.6928 - accuracy: 0.5010
3640/3640 [==============================] - 4s 1ms/step - loss: 0.6929 - accuracy: 0.5000
Epoch 1/2
18197/18197 [==============================] - 27s 1ms/step - loss: 0.4782 - accuracy: 0.7884
Epoch 2/2
18197/18197 [==============================] - 25s 1ms/step - loss: 0.3179 - accuracy: 0.8836
Best:  0sing {&#39;activation&#39;: &#39;relu&#39;, &#39;init_weights&#39;: &#39;uniform&#39;, &#39;optimizer&#39;: &#39;RMSprop&#39;}
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">ypred_ann</span> <span class="o">=</span> <span class="n">grid</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span><span class="n">ypred_ann</span><span class="p">))</span>
<span class="n">score_ann</span> <span class="o">=</span>  <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span> <span class="n">ypred_ann</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The ROC_AUC Score from the ANN after grid search is &quot;</span> <span class="p">,</span> <span class="n">score_ann</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>              precision    recall  f1-score   support

           0       1.00      1.00      1.00     56864
           1       0.26      0.81      0.39        98

    accuracy                           1.00     56962
   macro avg       0.63      0.90      0.69     56962
weighted avg       1.00      1.00      1.00     56962

The ROC_AUC Score from the ANN after grid search is  0.9010388553282879
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>APPLYING ANOMALY DETECTION ALGORITHMS</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong><em>Outlier detection model</em></strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span><span class="n">Y</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>((182276, 30), (227845,))</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">sklearn</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">svm</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span><span class="n">cross_validate</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span><span class="n">classification_report</span><span class="p">,</span><span class="n">f1_score</span><span class="p">,</span><span class="n">accuracy_score</span>
<span class="n">X</span><span class="o">=</span> <span class="n">data_train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;Class&#39;</span><span class="p">,</span><span class="n">axis</span> <span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">data_train</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span>
<span class="n">ytest</span> <span class="o">=</span> <span class="n">data_test_hidden</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span>
<span class="n">Xtrain</span><span class="p">,</span> <span class="n">Xval</span><span class="p">,</span> <span class="n">Ytrain</span><span class="p">,</span> <span class="n">Yval</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">Y</span><span class="p">)</span>
<span class="c1">#define outlier detection model</span>
<span class="n">model_svm</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">OneClassSVM</span><span class="p">(</span><span class="n">gamma</span><span class="o">=</span><span class="s1">&#39;scale&#39;</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="mf">0.00172</span><span class="p">)</span>
<span class="c1"># fit on majority class</span>

<span class="n">model_svm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">,</span><span class="n">Ytrain</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>OneClassSVM(nu=0.00172)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span><span class="n">Y</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>((227845, 30), (227845,))</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1"># detect outliers in the test set</span>
<span class="n">yhat_svm</span> <span class="o">=</span> <span class="n">model_svm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">yhat_svm</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>[1 1 1 ... 1 1 1]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">data_test_hidden</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0        0
1        0
2        0
3        0
4        0
        ..
56957    0
56958    0
56959    0
56960    0
56961    0
Name: Class, Length: 56962, dtype: int64</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">YTEST</span> <span class="o">=</span> <span class="n">data_test_hidden</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">YTEST</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>0        0
1        0
2        0
3        0
4        0
        ..
56957    0
56958    0
56959    0
56960    0
56961    0
Name: Class, Length: 56962, dtype: int64
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1"># mark inliers 1, outliers -1 for the test set (YTEST)</span>
<span class="n">YTEST</span><span class="p">[</span><span class="n">YTEST</span><span class="o">==</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="n">YTEST</span><span class="p">[</span><span class="n">YTEST</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  
/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  This is separate from the ipykernel package so we can avoid doing imports until
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">YTEST</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0        1
1        1
2        1
3        1
4        1
        ..
56957    1
56958    1
56959    1
56960    1
56961    1
Name: Class, Length: 56962, dtype: int64</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">f1_score</span><span class="p">(</span><span class="n">YTEST</span><span class="p">,</span><span class="n">yhat_svm</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>0.9975714486836548
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">YTEST</span><span class="p">,</span><span class="n">yhat_svm</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>              precision    recall  f1-score   support

          -1       0.00      0.00      0.00        98
           1       1.00      1.00      1.00     56864

    accuracy                           1.00     56962
   macro avg       0.50      0.50      0.50     56962
weighted avg       1.00      1.00      1.00     56962

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">ytest</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>(56962,)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">Y_train</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>((182276, 30), 0    181961
 1       315
 Name: Class, dtype: int64)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Isolation-Forest"><strong><em>Isolation Forest</em></strong><a class="anchor-link" href="#Isolation-Forest">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">IsolationForest</span>

<span class="n">model_if</span> <span class="o">=</span> <span class="n">IsolationForest</span><span class="p">(</span><span class="n">contamination</span><span class="o">=</span><span class="mf">0.00172</span><span class="p">,</span><span class="n">max_features</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span><span class="n">Y</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>((227845, 30), (227845,))</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">x3train</span><span class="p">,</span><span class="n">x3val</span><span class="p">,</span><span class="n">y3train</span><span class="p">,</span><span class="n">y3val</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">stratify</span> <span class="o">=</span> <span class="n">Y</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1"># fit on majority class</span>

<span class="n">model_if</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  &#34;X does not have valid feature names, but&#34;
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>IsolationForest(contamination=0.00172, max_features=10, random_state=32)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">y3train</span><span class="p">[:</span><span class="mi">100</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>164956    0
152233    0
160314    0
70280     0
80279     0
         ..
78334     0
60646     0
62411     0
87082     0
31749     0
Name: Class, Length: 100, dtype: int64
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1"># mark inliers 1, outliers -1 for the test set</span>
<span class="n">y3train</span><span class="p">[</span><span class="n">y3train</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="n">y3train</span><span class="p">[</span><span class="n">y3train</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">y3train</span><span class="p">[:</span><span class="mi">100</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>164956    1
152233    1
160314    1
70280     1
80279     1
         ..
78334     1
60646     1
62411     1
87082     1
31749     1
Name: Class, Length: 100, dtype: int64
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">yhat_if_x3train</span> <span class="o">=</span> <span class="n">model_if</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x3train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">score_if_tr</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y3train</span><span class="p">,</span> <span class="n">yhat_if_x3train</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">score_if_tr</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>0.275974025974026
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Predicting anomaly detection by isolation forest on the train data set</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">data_test</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(56962, 30)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">data_test</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(56962, 30)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y3train</span><span class="p">,</span> <span class="n">yhat_if_x3train</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>              precision    recall  f1-score   support

          -1       0.28      0.27      0.28       315
           1       1.00      1.00      1.00    181961

    accuracy                           1.00    182276
   macro avg       0.64      0.63      0.64    182276
weighted avg       1.00      1.00      1.00    182276

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Predicting anomaly detection by isolation forest on the test data set</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">yhat_if_test</span> <span class="o">=</span> <span class="n">model_if</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data_test</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">YTEST</span><span class="p">,</span> <span class="n">yhat_if_test</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>              precision    recall  f1-score   support

          -1       0.26      0.26      0.26        98
           1       1.00      1.00      1.00     56864

    accuracy                           1.00     56962
   macro avg       0.63      0.63      0.63     56962
weighted avg       1.00      1.00      1.00     56962

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong><em>Elliptic Envelope</em></strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.covariance</span> <span class="kn">import</span> <span class="n">EllipticEnvelope</span>
<span class="c1"># EllipticEnvelope model</span>
<span class="n">model_EE</span> <span class="o">=</span> <span class="n">EllipticEnvelope</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span><span class="n">assume_centered</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># fit on majority class</span>

<span class="n">model_EE</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-144.313516062779598 &gt; -220.662913186000424). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-142.007472073423514 &gt; -142.776150930738339). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-137.454393831662856 &gt; -137.554541664859528). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-134.449817614396181 &gt; -134.861421336805165). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-185.864461568732196 &gt; -213.026989299508585). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-192.875807000791553 &gt; -217.775898013560919). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-139.519985296061833 &gt; -139.886736448789094). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-113.571515384986753 &gt; -114.862515426107421). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-117.491676457855164 &gt; -140.007279388364168). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-124.233242569033749 &gt; -124.440777455662669). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-120.318153279587449 &gt; -224.019508365502048). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-117.615999177950641 &gt; -219.131807194705289). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-122.738540837033426 &gt; -216.926185034767656). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-118.433875673855880 &gt; -138.923681006388222). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-109.314085684610006 &gt; -213.237150700848275). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-141.294065190096745 &gt; -142.387852772105731). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-135.038374259994356 &gt; -137.961462936991097). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-140.212371203711086 &gt; -142.502572542736203). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-146.743820800283260 &gt; -163.641468913371625). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-142.191098062079362 &gt; -169.576048673120766). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-146.950843660693636 &gt; -162.637980329625265). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-144.505492905233297 &gt; -165.897718153540836). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-154.950059603474955 &gt; -182.675805635400451). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-156.963794660673528 &gt; -210.572982602036888). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-123.907975603809504 &gt; -217.709190820077566). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-122.302041877099555 &gt; -217.951924441586129). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-140.513713511711273 &gt; -217.730620988052863). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-139.883692827608542 &gt; -140.505404683532419). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-124.275645041561887 &gt; -221.151594139045358). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-133.429911801958639 &gt; -158.502662239550062). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-164.738632269984066 &gt; -170.295022185074970). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-109.253726442864178 &gt; -211.343494058748377). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-138.895631828333961 &gt; -140.240536033056742). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-141.073626889044334 &gt; -141.317091123461694). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-140.477645049469174 &gt; -143.060075447654498). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-139.598629704108731 &gt; -142.244899824066920). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-118.525003736820622 &gt; -217.527929277433486). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-143.981300710893407 &gt; -146.746465027259063). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-143.292827130228090 &gt; -143.708254176412566). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-133.837094722534005 &gt; -161.115659581436489). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-153.302252742241762 &gt; -167.842873057035888). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-149.764818516186097 &gt; -220.547411040379359). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-144.347851197096531 &gt; -222.060572340662929). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-163.967035781479581 &gt; -168.030508987319990). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-123.563019126037830 &gt; -198.713127345624144). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-161.748777046815860 &gt; -163.223783706242216). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-124.101286319695305 &gt; -217.929235320526686). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-111.791286520297689 &gt; -214.036482212069615). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-156.432220930064403 &gt; -156.768382837754928). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-111.411266236150240 &gt; -215.441968686436383). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-110.744540377836017 &gt; -214.106405247073241). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-134.665970148704616 &gt; -135.414693978109511). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-133.383972150121451 &gt; -134.671247065487222). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-109.497895573732364 &gt; -219.075065394078905). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-139.978980545601985 &gt; -164.430267626147383). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-137.396994495177495 &gt; -163.415186237692467). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-136.758052916869502 &gt; -164.340706701503848). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-138.023739903055088 &gt; -163.156502515876809). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-138.714817904040729 &gt; -141.310753124878545). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-110.375165552647204 &gt; -216.296116159921382). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-115.565746860798896 &gt; -137.327055548122672). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-121.935981432441679 &gt; -216.321681175612923). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-154.242626802533152 &gt; -155.470516678545238). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-128.650855712066431 &gt; -220.977664648401571). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-124.200854018554480 &gt; -192.484132540284776). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-140.474290856247876 &gt; -142.929452108153100). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-142.454362656063324 &gt; -143.847944997550400). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-141.722328312779240 &gt; -141.752395556866077). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-138.981183209771189 &gt; -220.623289090818503). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-115.774005443380275 &gt; -217.286256760158551). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-131.973700871476353 &gt; -134.999423646593556). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-140.164359844846331 &gt; -161.345968267970562). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-139.039357830484334 &gt; -162.033040317795439). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-123.250853494138681 &gt; -218.777156320010192). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-135.153067178405593 &gt; -160.305767993757087). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-144.328702480804935 &gt; -219.445224933910993). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-87.207184855362030 &gt; -269.413451136825188). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-119.273370248271675 &gt; -218.724761644918118). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-138.177368793014296 &gt; -159.250319092934603). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-148.346599189463120 &gt; -164.334823682352010). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-140.110554070378981 &gt; -140.553131747782999). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-109.567165703173956 &gt; -214.665599679833633). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-108.223865899130999 &gt; -209.432094270772751). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-123.775690453527801 &gt; -219.882711447693708). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-134.983861703400237 &gt; -135.510118126418888). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-138.493825440227909 &gt; -140.272384392911874). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-142.280525556222756 &gt; -143.094306771288331). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-138.410269832545623 &gt; -161.444195074216623). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-119.011135931026274 &gt; -219.785684394767287). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-125.348347094979118 &gt; -218.617336596355244). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-114.000105570768412 &gt; -220.321089471619018). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-140.292882916732424 &gt; -143.205869428914838). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-140.022167070637266 &gt; -164.334780238696652). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-139.701310318199944 &gt; -166.431793998820410). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-146.219240410272960 &gt; -148.522240952242385). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-125.505801851771878 &gt; -199.911867113309256). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-110.639674664728290 &gt; -217.129422046308946). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-122.586994233595320 &gt; -219.627851200750172). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-145.336071422708585 &gt; -222.232593663766181). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-137.731260574931468 &gt; -138.185685502206411). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-107.396444128967957 &gt; -212.539955173153203). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-145.087535522878511 &gt; -149.006513797313659). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-149.140960196317280 &gt; -222.063713594666893). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-146.947155250185489 &gt; -222.691456564398720). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-115.070411143806396 &gt; -221.106416652044260). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-157.745643183412511 &gt; -158.374208598774658). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-142.098647760531833 &gt; -171.692956439816157). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-119.926767045908605 &gt; -214.572959724970644). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-124.653388129700048 &gt; -223.492241756559082). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-184.948921275873971 &gt; -217.098685651916327). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-145.439664471423129 &gt; -168.082884146043483). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-117.709496978329994 &gt; -117.932613746069961). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-121.745752818480071 &gt; -215.063102466287830). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-116.775159517357139 &gt; -119.739494993813722). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-114.757797793327001 &gt; -216.867306629181087). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-147.036127036178385 &gt; -169.959705369253243). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-144.120436906016323 &gt; -219.245342932457504). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-140.111165340659426 &gt; -161.779199579830845). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-146.280984014746792 &gt; -171.656246754154608). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-139.301579935769837 &gt; -140.113769055641171). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-166.709245712996591 &gt; -185.482469563915089). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-142.654276720533574 &gt; -145.522382620742491). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-196.765166488061254 &gt; -202.742968908169388). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-118.186830030567435 &gt; -222.426670149806370). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-144.380671941539617 &gt; -163.858894807393995). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-138.622235283326091 &gt; -138.655096278384775). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-118.399253039881529 &gt; -220.452081464895741). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-129.741325382129020 &gt; -154.690470341548377). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-145.097536304471504 &gt; -221.057702580192085). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-146.789296740502067 &gt; -169.243036841961896). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-123.300178976450184 &gt; -218.559793541993997). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-144.026736555216729 &gt; -223.542936137567608). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-125.532424778456601 &gt; -126.195273690046264). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-135.694842618253830 &gt; -157.827866368740985). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-124.041917092791991 &gt; -218.088608480464529). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-131.124852806084647 &gt; -154.338843668575237). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-155.532079783087113 &gt; -156.065974934892267). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-161.482607340728833 &gt; -164.971254205098660). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-110.209526786770766 &gt; -213.762990043287147). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-135.892579185071611 &gt; -155.207567113819323). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-146.093677976247562 &gt; -165.681325022855447). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-112.384843041904702 &gt; -243.128541677772859). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-123.435319865326406 &gt; -219.897256041597217). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-116.031507556144376 &gt; -221.383173433939703). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-149.270773607077672 &gt; -166.873812418197588). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-110.793836994936044 &gt; -212.470566886553257). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-140.952679364703187 &gt; -142.097232308815904). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-142.037380784895447 &gt; -143.415118120171854). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-144.767739404152877 &gt; -145.132361131001289). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-156.530670638530268 &gt; -158.328002284653479). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-125.472853272365114 &gt; -126.929965350029732). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-114.142443755837235 &gt; -215.016367857765317). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-121.205440298249300 &gt; -126.400937794226962). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-144.464812564556894 &gt; -145.242991360629304). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-127.775079882043656 &gt; -128.220694457164939). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-144.299952802012456 &gt; -146.493979960593606). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-138.909882866840064 &gt; -140.278150324261333). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-140.752510833997178 &gt; -141.413223582675812). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-140.048136356869492 &gt; -144.071579864947608). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-116.532421345684497 &gt; -118.481199995584475). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-121.974142735548682 &gt; -216.340651947672740). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-146.306879872458097 &gt; -169.152871443864001). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-109.447157373645538 &gt; -213.359043356105218). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-143.596729741412730 &gt; -145.958915334088488). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-138.645450468356188 &gt; -160.423763014352573). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-151.523005971908759 &gt; -181.427558704949519). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-123.546240009614564 &gt; -220.045210744763693). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-143.207162097714644 &gt; -220.354283328201006). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-146.734114669087347 &gt; -220.225686984260847). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-113.908863519722388 &gt; -134.445302260582451). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-145.085300176880224 &gt; -147.321609126058831). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-142.342928381733685 &gt; -169.612204384312463). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-146.182887394663169 &gt; -171.350750924337575). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-136.308253617600684 &gt; -137.316054986827993). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-114.611277926313377 &gt; -140.136706895841371). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-143.533324502822097 &gt; -161.219569290016324). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-133.278367649059646 &gt; -160.524562911354735). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-134.793168208531881 &gt; -161.166301302910028). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-136.630275831509749 &gt; -160.132606057529756). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-140.813796428598607 &gt; -141.415667979645178). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-141.984108200480762 &gt; -220.725449317963125). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-155.518231319936120 &gt; -157.815560777273618). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-122.678517944041118 &gt; -221.670888017444156). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-109.857810559875759 &gt; -212.595244223579442). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-143.142058480679367 &gt; -222.447604689389891). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-122.837764061580089 &gt; -217.761451046134255). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-146.490775292638375 &gt; -169.836119249578388). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-110.088663110279668 &gt; -214.509433731005288). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-130.007435656747987 &gt; -153.524569515690786). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-144.234410402017829 &gt; -165.860856785136633). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-137.863975412041981 &gt; -164.059068609243553). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-138.714230376137522 &gt; -160.832660914838158). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-125.359814645957499 &gt; -219.712614651404778). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-122.927231833406708 &gt; -220.058164172890145). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-111.475284165109812 &gt; -112.246829093653730). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-124.749336106953066 &gt; -125.033212439666315). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-120.135733067901668 &gt; -217.217992206338863). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-140.947300441587458 &gt; -142.946196132830153). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-143.882024123751137 &gt; -168.072840118709905). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-159.110694023892478 &gt; -160.491861953325071). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-149.090127577774979 &gt; -167.100867114166704). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-143.457735921556292 &gt; -168.633333678360742). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-193.203122263651238 &gt; -222.594421888642557). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-139.815855871232060 &gt; -139.927581445616454). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-131.769981996371030 &gt; -159.319537614987951). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-122.224122273386072 &gt; -218.891579136700983). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-108.686298765463704 &gt; -212.511996827943676). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-141.412099149487005 &gt; -141.617800238979072). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-115.812552490846826 &gt; -216.581078473999298). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-119.898116386803878 &gt; -218.534835127513162). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-140.608989659462566 &gt; -161.581049215985900). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-145.221340719521947 &gt; -218.879635729873428). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-115.746898483927382 &gt; -212.057197904787444). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-149.313816658837027 &gt; -168.959606460168970). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-121.574437572949194 &gt; -219.286008232532936). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-127.122587007258403 &gt; -153.798999513509102). You may want to try with a higher value of support_fraction (current value: 0.500).
  RuntimeWarning,
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>EllipticEnvelope(assume_centered=True, random_state=32)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1"># predict outliers in the train set</span>
<span class="n">yhat_ee</span> <span class="o">=</span> <span class="n">model_EE</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x3train</span><span class="p">)</span>
<span class="c1"># calculate score</span>
<span class="n">F1_score_ee_train</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y3train</span><span class="p">,</span><span class="n">yhat_ee</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y3train</span><span class="p">,</span><span class="n">yhat_ee</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>              precision    recall  f1-score   support

          -1       0.01      0.57      0.02       315
           1       1.00      0.90      0.95    181961

    accuracy                           0.90    182276
   macro avg       0.50      0.73      0.48    182276
weighted avg       1.00      0.90      0.95    182276

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1"># predict outliers in the test set</span>
<span class="n">yhat_ee_test</span> <span class="o">=</span> <span class="n">model_EE</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data_test</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">YTEST</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>0        1
1        1
2        1
3        1
4        1
        ..
56957    1
56958    1
56959    1
56960    1
56961    1
Name: Class, Length: 56962, dtype: int64
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1"># Anomaly detection using Elliptic Envelope </span>

<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">YTEST</span><span class="p">,</span><span class="n">yhat_ee_test</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>              precision    recall  f1-score   support

          -1       0.01      0.57      0.02        98
           1       1.00      0.90      0.95     56864

    accuracy                           0.90     56962
   macro avg       0.50      0.74      0.48     56962
weighted avg       1.00      0.90      0.95     56962

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong><em>Local Outlier Factor</em></strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1"># define outlier detection model</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">vstack</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">LocalOutlierFactor</span>
<span class="n">model_lof</span> <span class="o">=</span> <span class="n">LocalOutlierFactor</span><span class="p">(</span><span class="n">contamination</span><span class="o">=</span><span class="mf">0.00172</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1"># make prediction on composite dataset</span>
<span class="n">yhat_lof</span> <span class="o">=</span> <span class="n">model_lof</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">x3train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y3train</span><span class="p">,</span><span class="n">yhat_lof</span><span class="p">))</span>
<span class="n">Score_LOF</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y3train</span><span class="p">,</span><span class="n">yhat_lof</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;F1 Score_LOF: </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">Score_LOF</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>              precision    recall  f1-score   support

          -1       0.04      0.04      0.04       315
           1       1.00      1.00      1.00    181961

    accuracy                           1.00    182276
   macro avg       0.52      0.52      0.52    182276
weighted avg       1.00      1.00      1.00    182276

F1 Score_LOF: 0.041
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">yhat_lof_test</span> <span class="o">=</span> <span class="n">model_lof</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">data_test</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">YTEST</span><span class="p">[:</span><span class="mi">100</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0     1
1     1
2     1
3     1
4     1
     ..
95    1
96    1
97    1
98    1
99    1
Name: Class, Length: 100, dtype: int64</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">ytest1</span><span class="o">=</span> <span class="n">data_test_hidden</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span>
<span class="n">ytest1</span><span class="p">[:</span><span class="mi">100</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0     1
1     1
2     1
3     1
4     1
     ..
95    1
96    1
97    1
98    1
99    1
Name: Class, Length: 100, dtype: int64</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">YTEST</span><span class="p">,</span><span class="n">yhat_lof_test</span><span class="p">))</span>
<span class="n">Score_LOF</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">YTEST</span><span class="p">,</span><span class="n">yhat_lof_test</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;F1 Score_LOF: </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">Score_LOF</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>              precision    recall  f1-score   support

          -1       0.00      0.00      0.00        98
           1       1.00      1.00      1.00     56864

    accuracy                           1.00     56962
   macro avg       0.50      0.50      0.50     56962
weighted avg       1.00      1.00      1.00     56962

F1 Score_LOF: 0.000
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Guassian mixture model</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.mixture</span> <span class="kn">import</span> <span class="n">GaussianMixture</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">X_train</span><span class="o">.</span><span class="n">columns</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>Index([&#39;Time&#39;, &#39;V1&#39;, &#39;V2&#39;, &#39;V3&#39;, &#39;V4&#39;, &#39;V5&#39;, &#39;V6&#39;, &#39;V7&#39;, &#39;V8&#39;, &#39;V9&#39;, &#39;V10&#39;,
       &#39;V11&#39;, &#39;V12&#39;, &#39;V13&#39;, &#39;V14&#39;, &#39;V15&#39;, &#39;V16&#39;, &#39;V17&#39;, &#39;V18&#39;, &#39;V19&#39;, &#39;V20&#39;,
       &#39;V21&#39;, &#39;V22&#39;, &#39;V23&#39;, &#39;V24&#39;, &#39;V25&#39;, &#39;V26&#39;, &#39;V27&#39;, &#39;V28&#39;, &#39;Amount&#39;],
      dtype=&#39;object&#39;)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">X</span><span class="o">.</span><span class="n">columns</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>Index([&#39;Time&#39;, &#39;V1&#39;, &#39;V2&#39;, &#39;V3&#39;, &#39;V4&#39;, &#39;V5&#39;, &#39;V6&#39;, &#39;V7&#39;, &#39;V8&#39;, &#39;V9&#39;, &#39;V10&#39;,
       &#39;V11&#39;, &#39;V12&#39;, &#39;V13&#39;, &#39;V14&#39;, &#39;V15&#39;, &#39;V16&#39;, &#39;V17&#39;, &#39;V18&#39;, &#39;V19&#39;, &#39;V20&#39;,
       &#39;V21&#39;, &#39;V22&#39;, &#39;V23&#39;, &#39;V24&#39;, &#39;V25&#39;, &#39;V26&#39;, &#39;V27&#39;, &#39;V28&#39;, &#39;Amount&#39;],
      dtype=&#39;object&#39;)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">gm</span> <span class="o">=</span> <span class="n">GaussianMixture</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">gm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data_test</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([0, 1, 0, ..., 0, 0, 1])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">GM</span> <span class="o">=</span> <span class="n">gm</span><span class="o">.</span><span class="n">score_samples</span><span class="p">(</span><span class="n">data_test</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">test_gm</span> <span class="o">=</span> <span class="n">data_test</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">gm</span><span class="o">.</span><span class="n">score_samples</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([-44.86589413, -53.77930778, -49.7629285 , ..., -59.96937686,
       -21.34146562, -26.00224435])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">gm</span><span class="o">.</span><span class="n">score_samples</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(182276,)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">gm</span><span class="o">.</span><span class="n">score_samples</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(227845,)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">df2</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df2</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(227845, 31)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">df2</span><span class="p">[</span><span class="s1">&#39;guassian_score&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gm</span><span class="o">.</span><span class="n">score_samples</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">df2</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(227845, 32)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">df2</span><span class="p">[</span><span class="s1">&#39;guassian_score&#39;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0        -22.093810
1        -54.642823
2        -47.652002
3        -42.735431
4        -23.913787
            ...    
227840   -50.450312
227841   -30.536064
227842   -30.394592
227843   -46.825714
227844   -49.150413
Name: guassian_score, Length: 227845, dtype: float64</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">df2</span><span class="p">[</span><span class="s1">&#39;guassian_score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span><span class="n">df2</span><span class="p">[</span><span class="s1">&#39;guassian_score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(-153925.88178474986, -18.384442437659583)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">norm</span> <span class="o">=</span> <span class="n">df2</span><span class="p">[</span><span class="n">df2</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">fraud1</span> <span class="o">=</span><span class="n">df2</span><span class="p">[</span><span class="n">df2</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">norm</span><span class="p">[</span><span class="s1">&#39;guassian_score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span><span class="n">norm</span><span class="p">[</span><span class="s1">&#39;guassian_score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(-7052.343280013169, -18.384442437659583)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">fraud1</span><span class="p">[</span><span class="s1">&#39;guassian_score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span><span class="n">fraud1</span><span class="p">[</span><span class="s1">&#39;guassian_score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(-153925.88178474986, -21.383907875508402)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="c1">#plt.style.use(&#39;seaborn-whitegrid&#39;)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">norm</span><span class="p">[</span><span class="s1">&#39;guassian_score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span><span class="n">fraud1</span><span class="p">[</span><span class="s1">&#39;guassian_score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>((227451,), (394,))</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">y</span> <span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">227451</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">y2</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">394</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Visualising the probability scores of fraudulent and non-fraudulent transactions</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">norm</span><span class="p">[</span><span class="s1">&#39;guassian_score&#39;</span><span class="p">],</span><span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;PROBABILITY SCORES FOR NORMAL TRANSACTIONS&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;probability scores&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>Text(0.5, 0, &#39;probability scores&#39;)</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">fraud1</span><span class="p">[</span><span class="s1">&#39;guassian_score&#39;</span><span class="p">],</span><span class="n">y2</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;PROBABILITY SCORES FOR FRAUD TRANSACTIONS&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;probability scores&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>Text(0.5, 0, &#39;probability scores&#39;)</pre>
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1"># set a threshold for markng a transcation as fraud or normal.</span>
<span class="c1">#setting threhold as 3500</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1"># Running isolation forest again using the Guassian scores as an engineered feature</span>

<span class="n">test_data_gm</span> <span class="o">=</span> <span class="n">data_test</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">test_data_gm</span><span class="p">[</span><span class="s1">&#39;guassian_score&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">GM</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">df2</span><span class="o">.</span><span class="n">columns</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>Index([&#39;Time&#39;, &#39;V1&#39;, &#39;V2&#39;, &#39;V3&#39;, &#39;V4&#39;, &#39;V5&#39;, &#39;V6&#39;, &#39;V7&#39;, &#39;V8&#39;, &#39;V9&#39;, &#39;V10&#39;,
       &#39;V11&#39;, &#39;V12&#39;, &#39;V13&#39;, &#39;V14&#39;, &#39;V15&#39;, &#39;V16&#39;, &#39;V17&#39;, &#39;V18&#39;, &#39;V19&#39;, &#39;V20&#39;,
       &#39;V21&#39;, &#39;V22&#39;, &#39;V23&#39;, &#39;V24&#39;, &#39;V25&#39;, &#39;V26&#39;, &#39;V27&#39;, &#39;V28&#39;, &#39;Amount&#39;,
       &#39;Class&#39;, &#39;guassian_score&#39;],
      dtype=&#39;object&#39;)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">Xtrain_gm</span> <span class="o">=</span> <span class="n">df2</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;Class&#39;</span><span class="p">,</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">Ytrain_gm</span> <span class="o">=</span> <span class="n">df2</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span>
<span class="n">model_if</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xtrain_gm</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  &#34;X does not have valid feature names, but&#34;
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>IsolationForest(contamination=0.00172, max_features=10, random_state=32)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">ypred_gm</span> <span class="o">=</span> <span class="n">model_if</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_data_gm</span> <span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">YTEST</span><span class="p">,</span><span class="n">ypred_gm</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>              precision    recall  f1-score   support

          -1       0.24      0.23      0.24        98
           1       1.00      1.00      1.00     56864

    accuracy                           1.00     56962
   macro avg       0.62      0.62      0.62     56962
weighted avg       1.00      1.00      1.00     56962

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">model_EE</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xtrain_gm</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-88.114847749191767 &gt; -89.026402693890120). You may want to try with a higher value of support_fraction (current value: 0.503).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-95.014008633495095 &gt; -115.760375006230007). You may want to try with a higher value of support_fraction (current value: 0.503).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-107.500442252105216 &gt; -211.736180520549908). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-106.240853755543156 &gt; -212.908134026480695). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-131.825999311441791 &gt; -212.122700604436289). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-142.802539321486051 &gt; -218.333376590663335). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-137.264070600130879 &gt; -138.098559150679307). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-137.112898302154406 &gt; -137.848966337639922). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-106.376672788685411 &gt; -214.706896765169489). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-106.185269295742685 &gt; -214.074654799803426). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-135.010628261529376 &gt; -135.762414013999575). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-137.883297215719665 &gt; -164.557842718526246). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-140.068031334024994 &gt; -140.602990764075429). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-161.850184349970306 &gt; -240.777537386371336). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-141.582028514778273 &gt; -141.788863688138235). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-107.345011995711729 &gt; -210.520238590498423). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-141.221164537738872 &gt; -214.025825623051247). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-120.734640410038082 &gt; -225.852912035953352). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-214.888291939763008 &gt; -219.626225411477606). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-140.094245165985825 &gt; -161.069460717949056). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-106.669155775369333 &gt; -208.486136149670472). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-137.241034910577440 &gt; -137.909166632545379). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-152.814135249543938 &gt; -202.600653014671906). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-107.210397649598846 &gt; -209.268378883142645). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-120.142293518746456 &gt; -222.015680213624194). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-139.190953276654227 &gt; -164.594407082358600). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-129.985279303984782 &gt; -154.121350845546175). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-139.940444989497308 &gt; -218.301318682003114). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-106.334413471253754 &gt; -209.913917589546656). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-107.138399495084300 &gt; -185.505721513719749). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-135.468698804316119 &gt; -164.397279719841151). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-140.737192949785452 &gt; -220.024497881710232). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-121.752979803501262 &gt; -218.489300567594825). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-121.084394709682059 &gt; -218.995659064652330). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-117.642728696407175 &gt; -215.415625305490835). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-107.741465011855468 &gt; -210.876527939156176). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-137.108768820675721 &gt; -164.500036421111162). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-153.997948336531351 &gt; -155.921762785266395). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-155.833915181839075 &gt; -156.650979142632991). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-114.420926062644099 &gt; -216.944379493426482). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-125.329047241038921 &gt; -126.921647458199971). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-122.828362223410721 &gt; -219.222578105658414). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-136.019496537600475 &gt; -137.884757532216838). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-117.736080993203828 &gt; -217.549518436690306). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-137.676023038319244 &gt; -140.982205074781490). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-111.429660328888644 &gt; -215.078652485344577). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-107.843178366967265 &gt; -207.991810212442743). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-143.167567438899937 &gt; -219.048231657272936). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-137.731980992689870 &gt; -160.168688278018806). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-122.031309843509760 &gt; -213.543408127253059). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-121.041549516184645 &gt; -218.065781512249941). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-133.800442323156801 &gt; -153.775938612029620). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-121.922254436728565 &gt; -217.088134397518076). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-133.442818365088613 &gt; -156.642999855887268). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-120.223851892459734 &gt; -218.142444031085688). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-145.030120482345723 &gt; -159.404486963499068). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-116.235047353046824 &gt; -243.726875705212734). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-110.714935917145027 &gt; -216.012026937883235). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-108.753873196572414 &gt; -212.947600521842020). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-135.789186159333781 &gt; -164.362975180354255). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-142.073877162198329 &gt; -217.211033131972982). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-136.081886570965878 &gt; -136.248380267681625). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-138.769659132902063 &gt; -138.827583971101120). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-140.273958986532250 &gt; -142.596914264755100). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-144.757723263449321 &gt; -158.535112087756147). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-143.307344396040094 &gt; -222.247960772183120). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-107.788863984509632 &gt; -208.528420544195768). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-107.419993011830670 &gt; -213.513569323655986). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-109.208314871713782 &gt; -212.817161999044231). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-137.817396270376832 &gt; -140.261094007185534). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-140.811223404352063 &gt; -144.873399288938742). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-140.088495417353982 &gt; -140.339182391758669). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-118.841996238190362 &gt; -188.630663255202109). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-136.712380671296302 &gt; -137.359840861515067). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-106.547761425985613 &gt; -210.136326171057391). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-141.579462151181673 &gt; -218.894645997587901). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-106.524253357837836 &gt; -210.713274711597563). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-107.514146510599247 &gt; -213.274751498749993). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-118.704599989986917 &gt; -216.792625649198442). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-121.084394709682059 &gt; -217.597863055959692). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-115.275006172185755 &gt; -215.587305783120769). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-120.375917667779177 &gt; -216.640083971355352). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-134.483666578019921 &gt; -161.775875446674718). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-109.837570857503437 &gt; -209.070403527396309). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-139.644753547286427 &gt; -162.872960276612531). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-106.410978562281372 &gt; -209.354446384308773). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-140.308507337346612 &gt; -163.360702953583768). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-121.087820685397801 &gt; -220.262348338276468). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-138.780196901583992 &gt; -141.356360914844487). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-139.359814998782582 &gt; -164.078942115814840). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-110.304437259379270 &gt; -129.639665469151396). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-141.423646562155710 &gt; -142.326851640628206). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-132.275549804353290 &gt; -155.753699432924350). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-133.096292913749920 &gt; -136.855645069305581). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-118.798076290029201 &gt; -212.365372664719587). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-137.564846762891307 &gt; -164.690689076716893). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-139.259419740519377 &gt; -164.482811320653411). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-109.243742448960745 &gt; -212.161335252012407). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-106.411501343650912 &gt; -207.451277915851591). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-137.662064447036357 &gt; -138.225785256506668). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-113.571201879483624 &gt; -214.415022709565903). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-140.622127614736598 &gt; -218.344705490270428). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-107.500442252105216 &gt; -212.317113524995932). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-188.272754169861742 &gt; -188.753036110381174). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-139.083675069879746 &gt; -276.193499865399360). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-154.135524218457590 &gt; -182.125334608721829). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-118.590253265076186 &gt; -212.624473072905687). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-141.695132388485433 &gt; -217.856009490285544). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-120.676488885402122 &gt; -217.704944768301544). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-135.245457740087829 &gt; -155.379564012484622). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-151.787075842754120 &gt; -153.526845589817583). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-131.012659879687959 &gt; -155.793683623013806). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-139.007779510623379 &gt; -165.591169510867530). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-114.407344871252647 &gt; -211.404066233109944). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-126.689606507630046 &gt; -220.728272455128632). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-142.086106803958188 &gt; -221.495269723039002). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-138.687935577413469 &gt; -160.517592022711995). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-154.183379064246651 &gt; -156.135845193370585). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-133.798600066256284 &gt; -137.225560207195201). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-122.828362223410721 &gt; -223.124383815739947). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-162.899827335103026 &gt; -219.753910766654315). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-121.782931585581721 &gt; -190.572615349977042). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-183.019976393861242 &gt; -216.984686867558707). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-135.625492214163046 &gt; -138.311512844637633). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-112.698012288023904 &gt; -207.657446795944168). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-129.942684184546749 &gt; -153.259300480250999). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-105.872235950702503 &gt; -212.278305198644375). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-139.602232287978836 &gt; -214.993846606074072). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-156.395604888571114 &gt; -215.514517326830827). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-124.708679456381503 &gt; -220.325236422620094). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-167.496851190191194 &gt; -167.533931274214922). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-107.894278500057098 &gt; -210.471918724800048). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-153.855074098727641 &gt; -154.787235551208198). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-108.017482053295282 &gt; -210.382283852048545). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-99.033121168344778 &gt; -124.446969430190990). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-137.059992533498502 &gt; -137.716640102765808). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-107.451383709301254 &gt; -216.465232657292319). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-135.834857292839217 &gt; -165.863388319947887). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-153.291126074590835 &gt; -155.314463895448398). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-110.591124126521748 &gt; -196.288238384967940). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-130.258611514182320 &gt; -134.990069848320871). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-107.527914170049314 &gt; -210.950636221722135). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-141.126870063939435 &gt; -141.927051977092987). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-137.370377035130275 &gt; -137.456286971521649). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-138.812774221581890 &gt; -158.519525392772749). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-130.201322354867443 &gt; -154.707174429743020). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-140.009958902804982 &gt; -217.062501966929858). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-144.739267815855584 &gt; -163.993143705168080). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-108.754036573408712 &gt; -213.644677011703948). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-121.051954459760381 &gt; -217.400552745665095). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-108.572272478692483 &gt; -214.153229184213927). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-122.353659713852039 &gt; -216.714864069508195). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-139.678987207174941 &gt; -140.231240300720032). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-138.682306347622472 &gt; -138.940568872812122). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-138.583128625002416 &gt; -164.064574029310990). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-133.762604384620744 &gt; -162.851101391464510). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-135.746994392930787 &gt; -161.230115229041786). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-135.121861224441318 &gt; -156.191529972680939). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-144.557237346932112 &gt; -218.861105155528037). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-138.210494876762482 &gt; -139.225854348883729). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-106.789522671084285 &gt; -211.020893232276677). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-140.568799620799638 &gt; -143.529100210233139). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-135.831910638219114 &gt; -137.855900598132109). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-136.643166304700799 &gt; -138.483050840718647). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-109.421532303339035 &gt; -211.824630521537557). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-137.113551927985270 &gt; -139.506810811918712). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-123.043715065155780 &gt; -227.642283700075552). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-139.283352421599034 &gt; -162.337252622949734). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-109.445892532904892 &gt; -209.047845942895435). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-133.849558883315808 &gt; -165.283555472483783). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-107.414537927378973 &gt; -213.541477070242394). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-140.483711800513504 &gt; -160.504142492447755). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-144.698796849192632 &gt; -167.052686236815333). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-138.234713495176692 &gt; -139.643314648364054). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-139.715406665387746 &gt; -140.717463669613124). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-134.492892432831411 &gt; -134.664971911312648). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-146.821814241428768 &gt; -218.650410903376724). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-114.486555928813885 &gt; -216.150212628906189). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-106.765091891289842 &gt; -209.091875817348864). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-139.021999682426724 &gt; -166.039379793128660). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-135.324994886828421 &gt; -138.557434842314990). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-209.706603342812343 &gt; -219.361958321333930). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-105.992167611102616 &gt; -209.879761477920908). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-115.686837858268106 &gt; -247.408569089217082). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-153.527161203812170 &gt; -167.793900193680486). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-183.106192199294981 &gt; -211.325354477396274). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-108.190390149918912 &gt; -213.593377613785378). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-140.203928395320162 &gt; -221.472904642474447). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-137.274186280092295 &gt; -137.314009592360293). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-106.138339533524018 &gt; -211.115266067814559). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-141.774971494358653 &gt; -218.195122097604326). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-119.535313150930108 &gt; -212.512348456316488). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-142.674299948034388 &gt; -218.999275309060550). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/covariance/_robust_covariance.py:189: RuntimeWarning: Determinant has increased; this should not happen: log(det) &gt; log(previous_det) (-161.422408193908154 &gt; -166.162619001199232). You may want to try with a higher value of support_fraction (current value: 0.501).
  RuntimeWarning,
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>EllipticEnvelope(assume_centered=True, random_state=32)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">ytest</span><span class="p">[:</span><span class="mi">100</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0     1
1     1
2     1
3     1
4     1
     ..
95    1
96    1
97    1
98    1
99    1
Name: Class, Length: 100, dtype: int64</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">ypred_gm_ee</span> <span class="o">=</span> <span class="n">model_EE</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_data_gm</span> <span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">YTEST</span><span class="p">,</span><span class="n">ypred_gm_ee</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>              precision    recall  f1-score   support

          -1       0.01      0.77      0.03        98
           1       1.00      0.90      0.95     56864

    accuracy                           0.90     56962
   macro avg       0.51      0.83      0.49     56962
weighted avg       1.00      0.90      0.95     56962

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">model_svm</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">()</span>
<span class="n">model_svm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xtrain_gm</span><span class="p">,</span><span class="n">Ytrain_gm</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[&nbsp;]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>SVC()</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>SVM model Evaluation
On taining data</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>SVM model Evaluation On test data</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1"># Accuracy on test data</span>
<span class="n">X_test_predict_svm</span> <span class="o">=</span> <span class="n">model_svm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_data_gm</span><span class="p">)</span>
<span class="n">accuracy_test_svm</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">YTEST</span><span class="p">,</span><span class="n">X_test_predict_svm</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">YTEST</span><span class="p">,</span><span class="n">X_test_predict_svm</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>              precision    recall  f1-score   support

          -1       0.00      0.00      0.00      98.0
           0       0.00      0.00      0.00       0.0
           1       0.00      0.00      0.00   56864.0

    accuracy                           0.00   56962.0
   macro avg       0.00      0.00      0.00   56962.0
weighted avg       0.00      0.00      0.00   56962.0

</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy using SVM model on training data is &quot;</span><span class="p">,</span> <span class="n">accuracy_train_svm</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Accuracy using SVM model on training data is  0.9982718514779785
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy using SVM model on test data is &quot;</span><span class="p">,</span> <span class="n">accuracy_test_svm</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Accuracy using SVM model on test data is  0.0
</pre>
</div>
</div>

</div>
</div>

</div>
    </div>
  </div>
</body>

 


</html>
